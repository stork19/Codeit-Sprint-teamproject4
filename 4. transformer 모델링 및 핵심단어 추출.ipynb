{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MML transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU 환경에서 seed 고정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False # cudnn을 끄는 것이 메모리 효율에는 좋을 수 있습니다. 하지만 속도가 느려질 수 있습니다.\n",
    "\n",
    "seed_everything(42) # 원하는 seed 값으로 변경 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리 개선\n",
    "def preprocess_data(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    text_column_name = 'cleaned_question_text'\n",
    "    tone_label_name = 'tone_label'\n",
    "    intent_label_name = 'intent_label'\n",
    "\n",
    "    texts = df[text_column_name].tolist()\n",
    "    tone_labels = df[tone_label_name].tolist()\n",
    "    intent_labels = df[intent_label_name].tolist()\n",
    "\n",
    "    tokenized_texts = [text.split() for text in texts]\n",
    "\n",
    "    word_counts = Counter()\n",
    "    for text in tokenized_texts:\n",
    "        word_counts.update(text)\n",
    "\n",
    "    special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "    for token in special_tokens:\n",
    "        word_counts[token] = 0\n",
    "\n",
    "    vocab = {token: idx for idx, token in enumerate(word_counts)}\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    numericalized_texts = [[vocab.get(token, vocab['<unk>']) for token in text] for text in tokenized_texts]\n",
    "    numericalized_tone_labels = [int(label) for label in tone_labels] # tone label 정수형 변환\n",
    "    numericalized_intent_labels = [int(label) for label in intent_labels] # intent label 정수형 변환\n",
    "\n",
    "    return numericalized_texts, numericalized_tone_labels, numericalized_intent_labels, vocab, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset 클래스 수정\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tone_labels, intent_labels):\n",
    "        self.texts = texts\n",
    "        self.tone_labels = tone_labels\n",
    "        self.intent_labels = intent_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx]), torch.tensor(self.tone_labels[idx]), torch.tensor(self.intent_labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성 함수 수정\n",
    "def collate_batch(batch, pad_idx):\n",
    "    texts = [item[0] for item in batch]\n",
    "    tone_labels = torch.stack([item[1] for item in batch])\n",
    "    intent_labels = torch.stack([item[2] for item in batch])\n",
    "    padded_texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=pad_idx)\n",
    "    return padded_texts, tone_labels, intent_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfomer 모델 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head attention Class 정의\n",
    "class MyMHA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        print(f'd_model : {d_model}, num_heads : {num_heads}')\n",
    "\n",
    "        # 각 head의 임베딩 차원 : 각 머리당 처리될 차원 수\n",
    "        self.d_head = d_model // num_heads\n",
    "        print(f'각 머리당 처리될 차원 수 : {self.d_head}')\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)      # Linear() : 행렬 곱셈\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_z = nn.Linear(d_model, d_model)\n",
    "\n",
    "    # 머리 나누기\n",
    "    # 입력 데이터 모양: [50, 100, 512]\n",
    "    # 출력 데이터 모양: [50, 8, 100, 64]\n",
    "    def split_heads(self, x):\n",
    "        # shape before : [50, 100, 512]\n",
    "        batch_size = x.size(0)\n",
    "        # 데이터 모양: [50, 100, 8, 64]\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.d_head) # -1 : '그대로 유지' 명령어\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # batch_size_1, seq_len, d_model = x2.size()\n",
    "        # x2 = x2.view(batch_size_1, seq_len, self.num_heads, self.d_head)  # shape after : (50, 100, 8, 64)\n",
    "        # x2 = x2.transpose(1, 2)   # shape last : (50, 8, 100, 64)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # 유사성 계산\n",
    "    def dot_prod(self, q, k, v, mask=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        z = torch.matmul(probs, v)\n",
    "\n",
    "        return z, probs # z와 probs 모두 반환\n",
    "\n",
    "    # 머리 합치기\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        Z = x.transpose(1, 2)\n",
    "        Z = Z.contiguous().view(batch_size, -1, self.d_model) # 출력 데이터 모양: [50, 100, 512]\n",
    "        return Z\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        Q = self.split_heads(self.W_q(q))\n",
    "        K = self.split_heads(self.W_k(k))\n",
    "        V = self.split_heads(self.W_v(v))\n",
    "\n",
    "        attn_output, attn = self.dot_prod(Q, K, V, mask) # attn 받기\n",
    "\n",
    "        attn_output = self.combine_heads(attn_output)\n",
    "        output = self.W_z(attn_output)\n",
    "\n",
    "        return output, attn # output과 attn 모두 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward class 구현\n",
    "\n",
    "class MyFFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(MyFFN, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어 트랜스포머 인코더 구현\n",
    "\n",
    "class My_Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Encoder, self).__init__()\n",
    "\n",
    "        self.mha = MyMHA(d_model, num_heads)\n",
    "        self.ffn = MyFFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # attention 가중치 저장\n",
    "        z, attn = self.mha(x, x, x, mask) # attn 받기\n",
    "        z = self.layer_norm(x + z)\n",
    "        w = self.ffn(z)\n",
    "        z = self.layer_norm(w + z)\n",
    "        return z, attn # attn 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 인코딩 구현\n",
    "\n",
    "class My_Position(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(My_Position, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def pos_enc(self, seq_len):\n",
    "        pos = torch.arange(0, seq_len, 1).float().unsqueeze(1)\n",
    "        result = torch.zeros(seq_len, self.d_model)\n",
    "        twoi = torch.arange(0, self.d_model, 2).float()\n",
    "        result[:, 0::2] = torch.sin(pos / (10000 ** (twoi / self.d_model)))\n",
    "        result[:, 1::2] = torch.cos(pos / (10000 ** (twoi / self.d_model)))\n",
    "        return result.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pos = self.pos_enc(seq_len)\n",
    "        return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 구현\n",
    "class My_Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Decoder, self).__init__()\n",
    "\n",
    "        self.mha1 = MyMHA(d_model, num_heads)\n",
    "        self.mha2 = MyMHA(d_model, num_heads)\n",
    "        self.ffn = MyFFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, tgt_mask):\n",
    "        print(f'디코더 입력 데이터 모양 : {x.shape}')\n",
    "        # print(x[0])\n",
    "\n",
    "        # 디코더 self attention 부분\n",
    "        z = self.mha1(x, x, x, tgt_mask)\n",
    "        z = self.layer_norm(z + x)        # self.layer_norm(z) + self.layer_norm(x) 와 같은 값이 될 수 없다.\n",
    "        print(f'self attention 후 데이터 모양 : {z.shape}')\n",
    "\n",
    "        # 디코더 cross attention\n",
    "        y = self.mha2(z, enc_out, enc_out, src_mask)\n",
    "        y = self.layer_norm(y + z)\n",
    "        print(f'cross attention 후 데이터 모양 : {y.shape}')\n",
    "        # print(y[0])\n",
    "\n",
    "        # 마지막 feed forward\n",
    "        w = self.ffn(y)\n",
    "        z = self.layer_norm(w + y)\n",
    "        print(f'feed forward 후 데이터 모양 : {z.shape}')\n",
    "        # print(z[0])\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 자연어 트랜스포머 구성\n",
    "\n",
    "class My_Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, d_ff, vocab_size, num_tone_labels, num_intent_labels):\n",
    "        super(My_Transformer, self).__init__()\n",
    "\n",
    "        self.enc_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = My_Position(d_model)\n",
    "        self.enc_layers = nn.ModuleList([My_Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)])\n",
    "        self.tone_classifier = nn.Linear(d_model, num_tone_labels)\n",
    "        self.intent_classifier = nn.Linear(d_model, num_intent_labels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_embed = self.enc_embed(src)\n",
    "        pos = self.pos_enc(src_embed)\n",
    "        src_embed = src_embed + pos\n",
    "        enc_out = self.dropout(src_embed)\n",
    "        all_encoder_attn_weights = [] # 모든 레이어의 attention weights를 저장할 리스트\n",
    "        for layer in self.enc_layers:\n",
    "            enc_out, attn_weights = layer(enc_out, None)\n",
    "            all_encoder_attn_weights.append(attn_weights)\n",
    "        \n",
    "        tone_pred = self.tone_classifier(enc_out.mean(dim=1))\n",
    "        intent_pred = self.intent_classifier(enc_out.mean(dim=1))\n",
    "\n",
    "        return tone_pred, intent_pred, all_encoder_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 클래스 정의\n",
    "class My_Vocab:\n",
    "    def __init__(self, vocab_dict):\n",
    "        self.vocab = vocab_dict\n",
    "        self.itos = {i:s for s,i in vocab_dict.items()} # index to string 추가\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def get(self, token, default=None):\n",
    "      return self.vocab.get(token, default)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.itos[idx]\n",
    "\n",
    "    def save(self, path): # 저장 메서드 추가\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.vocab, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path): # 로드 메서드 추가\n",
    "        with open(path, 'rb') as f:\n",
    "            vocab_dict = pickle.load(f)\n",
    "        return cls(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(model, text, vocab, top_k=10, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(text, str):\n",
    "            tokenized_text = text.split()\n",
    "        elif isinstance(text, list):\n",
    "            tokenized_text = text\n",
    "        else:\n",
    "            raise TypeError(\"Input text must be a string or a list of strings.\")\n",
    "\n",
    "        numericalized_text = [vocab.get(token, vocab['<unk>']) for token in tokenized_text]\n",
    "        src = torch.tensor([numericalized_text]).to(device)\n",
    "        sequence_length = src.shape[1]\n",
    "\n",
    "        _, _, all_encoder_attn_weights = model(src)\n",
    "        print(\"Shape of all_encoder_attn_weights:\", [attn.shape for attn in all_encoder_attn_weights])\n",
    "\n",
    "        # 모든 레이어의 attention 가중치를 평균내는 올바른 방법\n",
    "        all_attn = []\n",
    "        for layer_attn in all_encoder_attn_weights:\n",
    "            # 각 head의 attention 가중치를 평균냄 (핵심!)\n",
    "            avg_head_attn = torch.mean(layer_attn[0], dim=0) # (seq_len, seq_len)\n",
    "            all_attn.append(avg_head_attn)\n",
    "\n",
    "        avg_attn_weights = torch.mean(torch.stack(all_attn), dim=0) # 레이어 평균\n",
    "        print(\"Shape of avg_attn_weights:\", avg_attn_weights.shape)\n",
    "\n",
    "        word_importances = avg_attn_weights.mean(dim=0)\n",
    "        print(\"Shape of word_importances:\", word_importances.shape)\n",
    "\n",
    "        # top_k 값 조정 (핵심 수정)\n",
    "        k = min(top_k, len(word_importances)) # top_k 와 텐서 길이 중 작은 값을 선택\n",
    "\n",
    "        top_indices = torch.topk(word_importances, k).indices.cpu().numpy()\n",
    "        keywords = [tokenized_text[i] for i in top_indices]\n",
    "\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_keyword_extraction(model, text, vocab, top_k=10, device=\"cpu\", w2v_model=None):\n",
    "    attention_keywords = extract_keywords(model, text, vocab, top_k, device)\n",
    "\n",
    "    okt = Okt()\n",
    "    nouns = okt.nouns(text) # 명사 추출\n",
    "\n",
    "    # TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([text])\n",
    "    tfidf_scores = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0]))\n",
    "    tfidf_keywords = sorted(tfidf_scores, key=tfidf_scores.get, reverse=True)[:top_k]\n",
    "\n",
    "    # TextRank (간단한 구현, 필요에 따라 라이브러리 사용 가능)\n",
    "    # 여기서는 명사 기반으로 간단하게 구현\n",
    "    textrank_keywords = nouns[:top_k] # 단순 빈도수 기반으로 상위 k개 추출. 더 정교한 TextRank 구현은 pke, summa 등의 라이브러리 활용 추천.\n",
    "\n",
    "    # 키워드 임베딩 (Word2Vec 활용)\n",
    "    if w2v_model:\n",
    "        combined_keywords = attention_keywords + tfidf_keywords + textrank_keywords\n",
    "        keyword_embeddings = []\n",
    "        valid_keywords = []\n",
    "\n",
    "        for keyword in combined_keywords:\n",
    "            try:\n",
    "                embedding = w2v_model.wv[keyword]\n",
    "                keyword_embeddings.append(embedding)\n",
    "                valid_keywords.append(keyword)\n",
    "            except KeyError:\n",
    "                pass # Word2Vec 모델에 없는 단어는 제외\n",
    "\n",
    "        if keyword_embeddings:\n",
    "            avg_embedding = np.mean(keyword_embeddings, axis=0)\n",
    "            similarities = cosine_similarity(keyword_embeddings, [avg_embedding])\n",
    "            top_k_indices_embedding = np.argsort(similarities.flatten())[::-1][:top_k]\n",
    "            final_keywords = [valid_keywords[i] for i in top_k_indices_embedding]\n",
    "        else:\n",
    "            final_keywords = attention_keywords # 임베딩이 없을 경우 attention 키워드 반환\n",
    "    else:\n",
    "        final_keywords = list(set(attention_keywords + tfidf_keywords + textrank_keywords))[:top_k]\n",
    "\n",
    "    return final_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 수 출력 함수\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "    print(table)\n",
    "    print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "    return total_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의 (데이터셋, 평가)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tone_labels, intent_labels):\n",
    "        self.texts = texts\n",
    "        self.tone_labels = tone_labels\n",
    "        self.intent_labels = intent_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = torch.tensor(self.texts[idx])  # 텍스트를 텐서로 변환\n",
    "        tone_label = torch.tensor(self.tone_labels[idx])  # tone label을 텐서로 변환\n",
    "        intent_label = torch.tensor(self.intent_labels[idx]) # intent label을 텐서로 변환\n",
    "        return text, tone_label, intent_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, tone_criterion, intent_criterion):\n",
    "    model.eval()\n",
    "    total_tone_loss = 0\n",
    "    total_intent_loss = 0\n",
    "    all_tone_preds = []\n",
    "    all_tone_labels = []\n",
    "    all_intent_preds = []\n",
    "    all_intent_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            src_data, tone_labels, intent_labels = batch\n",
    "            tone_pred, intent_pred, _ = model(src_data)\n",
    "\n",
    "            tone_loss = tone_criterion(tone_pred, tone_labels)\n",
    "            intent_loss = intent_criterion(intent_pred, intent_labels)\n",
    "\n",
    "            total_tone_loss += tone_loss.item()\n",
    "            total_intent_loss += intent_loss.item()\n",
    "\n",
    "            all_tone_preds.extend(torch.argmax(tone_pred, dim=-1).cpu().numpy())\n",
    "            all_tone_labels.extend(tone_labels.cpu().numpy())\n",
    "\n",
    "            all_intent_preds.extend(torch.argmax(intent_pred, dim=-1).cpu().numpy())\n",
    "            all_intent_labels.extend(intent_labels.cpu().numpy())\n",
    "    return total_tone_loss / len(data_loader), all_tone_preds, all_tone_labels, total_intent_loss / len(data_loader), all_intent_preds, all_intent_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 12\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "tot_epoch = 10\n",
    "batch_size = 24\n",
    "learning_rate = 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "numericalized_texts, numericalized_tone_labels, numericalized_intent_labels, vocab, vocab_size = preprocess_data('data/question_categorize.csv')\n",
    "pad_idx = vocab['<pad>']\n",
    "index_to_word = {index: word for word, index in vocab.items()}\n",
    "\n",
    "# 데이터 분할 (train, test, 계층적 샘플링 적용)\n",
    "train_texts, test_texts, train_tone_labels, test_tone_labels, train_intent_labels, test_intent_labels = train_test_split(\n",
    "    numericalized_texts, numericalized_tone_labels, numericalized_intent_labels, test_size=0.2, random_state=42, stratify=numericalized_intent_labels # stratify 추가\n",
    ")\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = TextDataset(train_texts, train_tone_labels, train_intent_labels)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "def create_dataframe(texts, tone_labels, intent_labels):\n",
    "    df = pd.DataFrame({\n",
    "        'numericalized_text': texts,\n",
    "        'tone_label': tone_labels,\n",
    "        'intent_label': intent_labels\n",
    "    })\n",
    "    return df\n",
    "\n",
    "train_df = create_dataframe(train_texts, train_tone_labels, train_intent_labels)\n",
    "test_df = create_dataframe(test_texts, test_tone_labels, test_intent_labels)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "train_df.to_csv('data/train_data.csv', index=False)\n",
    "test_df.to_csv('data/test_data.csv', index=False)\n",
    "\n",
    "print(\"Train data saved to train_data.csv\")\n",
    "print(\"Test data saved to test_data.csv\")\n",
    "\n",
    "# 원래 텍스트로 복원하여 저장\n",
    "def restore_text(numericalized_text, index_to_word):\n",
    "    return \" \".join([index_to_word.get(idx, '<unk>') for idx in numericalized_text])\n",
    "\n",
    "train_df['original_text'] = train_df['numericalized_text'].apply(lambda x: restore_text(x, index_to_word))\n",
    "test_df['original_text'] = test_df['numericalized_text'].apply(lambda x: restore_text(x, index_to_word))\n",
    "\n",
    "train_df.to_csv('data/train_data_with_text.csv', index=False)\n",
    "test_df.to_csv('data/test_data_with_text.csv', index=False)\n",
    "\n",
    "print(\"Train data with original text saved to train_data_with_text.csv\")\n",
    "print(\"Test data with original text saved to test_data_with_text.csv\")\n",
    "\n",
    "# 저장된 데이터 확인\n",
    "print(\"\\nTrain Data Head:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Data Head:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = TextDataset(train_texts, train_tone_labels, train_intent_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda batch: collate_batch(batch, pad_idx))\n",
    "print()\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "\n",
    "test_dataset = TextDataset(test_texts, test_tone_labels, test_intent_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda batch: collate_batch(batch, pad_idx))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "num_tone_labels = len(set(numericalized_tone_labels))\n",
    "num_intent_labels = len(set(numericalized_intent_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_intent_label의 수 : \", Counter(train_intent_labels))\n",
    "print(\"test_intent_label의 수 : \", Counter(test_intent_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "+----------------------------------+------------+\n",
      "|             Modules              | Parameters |\n",
      "+----------------------------------+------------+\n",
      "|         enc_embed.weight         |  2946048   |\n",
      "|   enc_layers.0.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.0.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.0.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.0.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_z.bias     |    512     |\n",
      "| enc_layers.0.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.0.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.0.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.0.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.0.layer_norm.weight  |    512     |\n",
      "|   enc_layers.0.layer_norm.bias   |    512     |\n",
      "|   enc_layers.1.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.1.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.1.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.1.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_z.bias     |    512     |\n",
      "| enc_layers.1.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.1.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.1.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.1.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.1.layer_norm.weight  |    512     |\n",
      "|   enc_layers.1.layer_norm.bias   |    512     |\n",
      "|   enc_layers.2.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.2.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.2.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.2.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_z.bias     |    512     |\n",
      "| enc_layers.2.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.2.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.2.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.2.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.2.layer_norm.weight  |    512     |\n",
      "|   enc_layers.2.layer_norm.bias   |    512     |\n",
      "|   enc_layers.3.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.3.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.3.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.3.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_z.bias     |    512     |\n",
      "| enc_layers.3.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.3.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.3.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.3.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.3.layer_norm.weight  |    512     |\n",
      "|   enc_layers.3.layer_norm.bias   |    512     |\n",
      "|   enc_layers.4.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.4.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.4.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.4.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_z.bias     |    512     |\n",
      "| enc_layers.4.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.4.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.4.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.4.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.4.layer_norm.weight  |    512     |\n",
      "|   enc_layers.4.layer_norm.bias   |    512     |\n",
      "|   enc_layers.5.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.5.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.5.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.5.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_z.bias     |    512     |\n",
      "| enc_layers.5.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.5.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.5.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.5.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.5.layer_norm.weight  |    512     |\n",
      "|   enc_layers.5.layer_norm.bias   |    512     |\n",
      "|   enc_layers.6.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.6.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.6.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.6.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.6.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.6.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.6.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.6.mha.W_z.bias     |    512     |\n",
      "| enc_layers.6.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.6.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.6.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.6.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.6.layer_norm.weight  |    512     |\n",
      "|   enc_layers.6.layer_norm.bias   |    512     |\n",
      "|   enc_layers.7.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.7.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.7.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.7.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.7.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.7.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.7.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.7.mha.W_z.bias     |    512     |\n",
      "| enc_layers.7.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.7.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.7.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.7.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.7.layer_norm.weight  |    512     |\n",
      "|   enc_layers.7.layer_norm.bias   |    512     |\n",
      "|   enc_layers.8.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.8.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.8.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.8.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.8.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.8.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.8.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.8.mha.W_z.bias     |    512     |\n",
      "| enc_layers.8.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.8.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.8.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.8.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.8.layer_norm.weight  |    512     |\n",
      "|   enc_layers.8.layer_norm.bias   |    512     |\n",
      "|   enc_layers.9.mha.W_q.weight    |   262144   |\n",
      "|    enc_layers.9.mha.W_q.bias     |    512     |\n",
      "|   enc_layers.9.mha.W_k.weight    |   262144   |\n",
      "|    enc_layers.9.mha.W_k.bias     |    512     |\n",
      "|   enc_layers.9.mha.W_v.weight    |   262144   |\n",
      "|    enc_layers.9.mha.W_v.bias     |    512     |\n",
      "|   enc_layers.9.mha.W_z.weight    |   262144   |\n",
      "|    enc_layers.9.mha.W_z.bias     |    512     |\n",
      "| enc_layers.9.ffn.linear1.weight  |  1048576   |\n",
      "|  enc_layers.9.ffn.linear1.bias   |    2048    |\n",
      "| enc_layers.9.ffn.linear2.weight  |  1048576   |\n",
      "|  enc_layers.9.ffn.linear2.bias   |    512     |\n",
      "|  enc_layers.9.layer_norm.weight  |    512     |\n",
      "|   enc_layers.9.layer_norm.bias   |    512     |\n",
      "|   enc_layers.10.mha.W_q.weight   |   262144   |\n",
      "|    enc_layers.10.mha.W_q.bias    |    512     |\n",
      "|   enc_layers.10.mha.W_k.weight   |   262144   |\n",
      "|    enc_layers.10.mha.W_k.bias    |    512     |\n",
      "|   enc_layers.10.mha.W_v.weight   |   262144   |\n",
      "|    enc_layers.10.mha.W_v.bias    |    512     |\n",
      "|   enc_layers.10.mha.W_z.weight   |   262144   |\n",
      "|    enc_layers.10.mha.W_z.bias    |    512     |\n",
      "| enc_layers.10.ffn.linear1.weight |  1048576   |\n",
      "|  enc_layers.10.ffn.linear1.bias  |    2048    |\n",
      "| enc_layers.10.ffn.linear2.weight |  1048576   |\n",
      "|  enc_layers.10.ffn.linear2.bias  |    512     |\n",
      "| enc_layers.10.layer_norm.weight  |    512     |\n",
      "|  enc_layers.10.layer_norm.bias   |    512     |\n",
      "|   enc_layers.11.mha.W_q.weight   |   262144   |\n",
      "|    enc_layers.11.mha.W_q.bias    |    512     |\n",
      "|   enc_layers.11.mha.W_k.weight   |   262144   |\n",
      "|    enc_layers.11.mha.W_k.bias    |    512     |\n",
      "|   enc_layers.11.mha.W_v.weight   |   262144   |\n",
      "|    enc_layers.11.mha.W_v.bias    |    512     |\n",
      "|   enc_layers.11.mha.W_z.weight   |   262144   |\n",
      "|    enc_layers.11.mha.W_z.bias    |    512     |\n",
      "| enc_layers.11.ffn.linear1.weight |  1048576   |\n",
      "|  enc_layers.11.ffn.linear1.bias  |    2048    |\n",
      "| enc_layers.11.ffn.linear2.weight |  1048576   |\n",
      "|  enc_layers.11.ffn.linear2.bias  |    512     |\n",
      "| enc_layers.11.layer_norm.weight  |    512     |\n",
      "|  enc_layers.11.layer_norm.bias   |    512     |\n",
      "|      tone_classifier.weight      |    1024    |\n",
      "|       tone_classifier.bias       |     2      |\n",
      "|     intent_classifier.weight     |    2048    |\n",
      "|      intent_classifier.bias      |     4      |\n",
      "+----------------------------------+------------+\n",
      "전체 모델 가중치 수: 40765446\n",
      "학습 시작\n",
      "Train Tone Confusion Matrix:\n",
      " [[ 249 1143]\n",
      " [   0 2562]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.30      1392\n",
      "           1       0.69      1.00      0.82      2562\n",
      "\n",
      "    accuracy                           0.71      3954\n",
      "   macro avg       0.85      0.59      0.56      3954\n",
      "weighted avg       0.80      0.71      0.64      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[   0  200   15  104]\n",
      " [   0 2101   12  143]\n",
      " [   0   92  380   46]\n",
      " [   0   17   14  830]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       319\n",
      "           1       0.87      0.93      0.90      2256\n",
      "           2       0.90      0.73      0.81       518\n",
      "           3       0.74      0.96      0.84       861\n",
      "\n",
      "    accuracy                           0.84      3954\n",
      "   macro avg       0.63      0.66      0.64      3954\n",
      "weighted avg       0.78      0.84      0.80      3954\n",
      "\n",
      "Epoch 1/10, Train Loss: 1.4267\n",
      "Time: 84.76s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1192  200]\n",
      " [  35 2527]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1392\n",
      "           1       0.93      0.99      0.96      2562\n",
      "\n",
      "    accuracy                           0.94      3954\n",
      "   macro avg       0.95      0.92      0.93      3954\n",
      "weighted avg       0.94      0.94      0.94      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[   0  228   23   68]\n",
      " [   0 2181   23   52]\n",
      " [   0   25  471   22]\n",
      " [   0   38    1  822]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       319\n",
      "           1       0.88      0.97      0.92      2256\n",
      "           2       0.91      0.91      0.91       518\n",
      "           3       0.85      0.95      0.90       861\n",
      "\n",
      "    accuracy                           0.88      3954\n",
      "   macro avg       0.66      0.71      0.68      3954\n",
      "weighted avg       0.81      0.88      0.84      3954\n",
      "\n",
      "Epoch 2/10, Train Loss: 0.8444\n",
      "Time: 83.39s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1235  157]\n",
      " [  17 2545]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93      1392\n",
      "           1       0.94      0.99      0.97      2562\n",
      "\n",
      "    accuracy                           0.96      3954\n",
      "   macro avg       0.96      0.94      0.95      3954\n",
      "weighted avg       0.96      0.96      0.96      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[  88  138   29   64]\n",
      " [   8 2175   25   48]\n",
      " [   1    0  515    2]\n",
      " [   2   13   18  828]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.28      0.42       319\n",
      "           1       0.94      0.96      0.95      2256\n",
      "           2       0.88      0.99      0.93       518\n",
      "           3       0.88      0.96      0.92       861\n",
      "\n",
      "    accuracy                           0.91      3954\n",
      "   macro avg       0.90      0.80      0.81      3954\n",
      "weighted avg       0.91      0.91      0.90      3954\n",
      "\n",
      "Epoch 3/10, Train Loss: 0.5952\n",
      "Time: 89.52s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1234  158]\n",
      " [   3 2559]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1392\n",
      "           1       0.94      1.00      0.97      2562\n",
      "\n",
      "    accuracy                           0.96      3954\n",
      "   macro avg       0.97      0.94      0.95      3954\n",
      "weighted avg       0.96      0.96      0.96      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 167  108   23   21]\n",
      " [  19 2200   24   13]\n",
      " [   6    0  511    1]\n",
      " [  10    5    0  846]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.52      0.64       319\n",
      "           1       0.95      0.98      0.96      2256\n",
      "           2       0.92      0.99      0.95       518\n",
      "           3       0.96      0.98      0.97       861\n",
      "\n",
      "    accuracy                           0.94      3954\n",
      "   macro avg       0.91      0.87      0.88      3954\n",
      "weighted avg       0.94      0.94      0.94      3954\n",
      "\n",
      "Epoch 4/10, Train Loss: 0.4661\n",
      "Time: 84.15s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1260  132]\n",
      " [   1 2561]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      1392\n",
      "           1       0.95      1.00      0.97      2562\n",
      "\n",
      "    accuracy                           0.97      3954\n",
      "   macro avg       0.98      0.95      0.96      3954\n",
      "weighted avg       0.97      0.97      0.97      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 129  171   15    4]\n",
      " [   3 2237   12    4]\n",
      " [   0    4  513    1]\n",
      " [   3   43    4  811]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.40      0.57       319\n",
      "           1       0.91      0.99      0.95      2256\n",
      "           2       0.94      0.99      0.97       518\n",
      "           3       0.99      0.94      0.96       861\n",
      "\n",
      "    accuracy                           0.93      3954\n",
      "   macro avg       0.95      0.83      0.86      3954\n",
      "weighted avg       0.94      0.93      0.92      3954\n",
      "\n",
      "Epoch 5/10, Train Loss: 0.4093\n",
      "Time: 89.74s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1326   66]\n",
      " [   3 2559]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      1392\n",
      "           1       0.97      1.00      0.99      2562\n",
      "\n",
      "    accuracy                           0.98      3954\n",
      "   macro avg       0.99      0.98      0.98      3954\n",
      "weighted avg       0.98      0.98      0.98      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 196  108   13    2]\n",
      " [   0 2238   13    5]\n",
      " [   0    0  518    0]\n",
      " [   5   11    0  845]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.61      0.75       319\n",
      "           1       0.95      0.99      0.97      2256\n",
      "           2       0.95      1.00      0.98       518\n",
      "           3       0.99      0.98      0.99       861\n",
      "\n",
      "    accuracy                           0.96      3954\n",
      "   macro avg       0.97      0.90      0.92      3954\n",
      "weighted avg       0.96      0.96      0.96      3954\n",
      "\n",
      "Epoch 6/10, Train Loss: 0.3118\n",
      "Time: 89.13s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1360   32]\n",
      " [  25 2537]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1392\n",
      "           1       0.99      0.99      0.99      2562\n",
      "\n",
      "    accuracy                           0.99      3954\n",
      "   macro avg       0.98      0.98      0.98      3954\n",
      "weighted avg       0.99      0.99      0.99      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 272   32   13    2]\n",
      " [  84 2159   11    2]\n",
      " [   0    0  514    4]\n",
      " [  14    4    1  842]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       319\n",
      "           1       0.98      0.96      0.97      2256\n",
      "           2       0.95      0.99      0.97       518\n",
      "           3       0.99      0.98      0.98       861\n",
      "\n",
      "    accuracy                           0.96      3954\n",
      "   macro avg       0.92      0.94      0.93      3954\n",
      "weighted avg       0.96      0.96      0.96      3954\n",
      "\n",
      "Epoch 7/10, Train Loss: 0.2870\n",
      "Time: 86.92s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1341   51]\n",
      " [   4 2558]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1392\n",
      "           1       0.98      1.00      0.99      2562\n",
      "\n",
      "    accuracy                           0.99      3954\n",
      "   macro avg       0.99      0.98      0.98      3954\n",
      "weighted avg       0.99      0.99      0.99      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 120  179   17    3]\n",
      " [   0 2246    8    2]\n",
      " [   0    4  513    1]\n",
      " [   0   28    3  830]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.38      0.55       319\n",
      "           1       0.91      1.00      0.95      2256\n",
      "           2       0.95      0.99      0.97       518\n",
      "           3       0.99      0.96      0.98       861\n",
      "\n",
      "    accuracy                           0.94      3954\n",
      "   macro avg       0.96      0.83      0.86      3954\n",
      "weighted avg       0.94      0.94      0.93      3954\n",
      "\n",
      "Epoch 8/10, Train Loss: 0.2279\n",
      "Time: 84.96s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1370   22]\n",
      " [  29 2533]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1392\n",
      "           1       0.99      0.99      0.99      2562\n",
      "\n",
      "    accuracy                           0.99      3954\n",
      "   macro avg       0.99      0.99      0.99      3954\n",
      "weighted avg       0.99      0.99      0.99      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 192  103   11   13]\n",
      " [   0 2227   15   14]\n",
      " [   0    1  516    1]\n",
      " [   0    1    0  860]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75       319\n",
      "           1       0.95      0.99      0.97      2256\n",
      "           2       0.95      1.00      0.97       518\n",
      "           3       0.97      1.00      0.98       861\n",
      "\n",
      "    accuracy                           0.96      3954\n",
      "   macro avg       0.97      0.90      0.92      3954\n",
      "weighted avg       0.96      0.96      0.96      3954\n",
      "\n",
      "Epoch 9/10, Train Loss: 0.1739\n",
      "Time: 84.14s\n",
      "\n",
      "Train Tone Confusion Matrix:\n",
      " [[1372   20]\n",
      " [  13 2549]]\n",
      "Train Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1392\n",
      "           1       0.99      0.99      0.99      2562\n",
      "\n",
      "    accuracy                           0.99      3954\n",
      "   macro avg       0.99      0.99      0.99      3954\n",
      "weighted avg       0.99      0.99      0.99      3954\n",
      "\n",
      "Train Intent Confusion Matrix:\n",
      " [[ 295   20    3    1]\n",
      " [   8 2241    6    1]\n",
      " [   1    3  514    0]\n",
      " [   5    3    0  853]]\n",
      "Train Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       319\n",
      "           1       0.99      0.99      0.99      2256\n",
      "           2       0.98      0.99      0.99       518\n",
      "           3       1.00      0.99      0.99       861\n",
      "\n",
      "    accuracy                           0.99      3954\n",
      "   macro avg       0.98      0.98      0.98      3954\n",
      "weighted avg       0.99      0.99      0.99      3954\n",
      "\n",
      "Epoch 10/10, Train Loss: 0.1567\n",
      "Time: 83.28s\n",
      "\n",
      "학습종료\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABMvUlEQVR4nO3deVxU5eIG8OfMAMM2g6zDIgjuioq4gIprooZmVqaWlma3W5Y7LVfvTc1Krcwy97R+7ZZb2uZOGmruiokiqCigsu/7MnN+fyCTBCLowJnl+X4+87ly5pyZZ+TWPL3ve84RRFEUQURERGQiZFIHICIiItInlhsiIiIyKSw3REREZFJYboiIiMiksNwQERGRSWG5ISIiIpPCckNEREQmheWGiIiITArLDREREZkUlhsiqpfnnnsOvr6+UscgIronlhsiIycIQr0eBw8elDpqNQcPHoQgCNi6davUUerl6tWreOmll9CyZUtYW1tDpVIhJCQEn3zyCYqLi6WOR0R3sJA6ABE9mG+++abaz19//TX27dtXY3uHDh0e6H02bNgArVb7QK9hrH777TeMGTMGCoUCEydORKdOnVBWVobDhw/j9ddfx4ULF7B+/XqpYxLRbSw3REbumWeeqfbzsWPHsG/fvhrb/6moqAi2trb1fh9LS8v7ymfsrl27hqeeegotWrTA77//Dg8PD91zU6dOxZUrV/Dbb7/p5b0KCwthZ2enl9ciMmecliIyAwMHDkSnTp1w+vRp9O/fH7a2tvjvf/8LAPjpp58wYsQIeHp6QqFQoFWrVnjnnXeg0WiqvcY/19xcv34dgiDgww8/xPr169GqVSsoFAr07NkTJ0+e1Fv2+Ph4jBkzBk5OTrC1tUWvXr1qLRMrV66Ev78/bG1t4ejoiB49emDjxo265/Pz8zFr1iz4+vpCoVDAzc0NQ4YMwZkzZ+p8/w8++AAFBQX4/PPPqxWbKq1bt8bMmTMB/P138uWXX9bYTxAEvPXWW7qf33rrLQiCgIsXL2L8+PFwdHRE37598eGHH0IQBCQkJNR4jblz58LKygrZ2dm6bcePH8fDDz8MBwcH2NraYsCAAThy5Eidn4nI1HHkhshMZGZmIiwsDE899RSeeeYZqNVqAMCXX34Je3t7hIeHw97eHr///jvmz5+PvLw8LF269J6vu3HjRuTn5+Oll16CIAj44IMP8MQTTyA+Pv6BR3tSU1PRp08fFBUVYcaMGXB2dsZXX32FRx99FFu3bsXjjz8OoHLKbMaMGXjyyScxc+ZMlJSU4K+//sLx48cxfvx4AMCUKVOwdetWTJs2DR07dkRmZiYOHz6MmJgYdOvW7a4ZfvnlF7Rs2RJ9+vR5oM9yN2PGjEGbNm2wePFiiKKIRx55BG+88QY2b96M119/vdq+mzdvxtChQ+Ho6AgA+P333xEWFobu3btjwYIFkMlk+OKLL/DQQw/h0KFDCAoKapTMRAZPJCKTMnXqVPGf/2gPGDBABCCuW7euxv5FRUU1tr300kuira2tWFJSots2adIksUWLFrqfr127JgIQnZ2dxaysLN32n376SQQg/vLLL3XmPHDggAhA3LJly133mTVrlghAPHTokG5bfn6+6OfnJ/r6+ooajUYURVEcNWqU6O/vX+f7OTg4iFOnTq1zn3/Kzc0VAYijRo2q1/5VfydffPFFjecAiAsWLND9vGDBAhGA+PTTT9fYt3fv3mL37t2rbTtx4oQIQPz6669FURRFrVYrtmnTRhw2bJio1Wp1+xUVFYl+fn7ikCFD6pWZyBRxWorITCgUCkyePLnGdhsbG92f8/PzkZGRgX79+qGoqAiXLl265+uOGzdON5IAAP369QNQOZ30oHbu3ImgoCD07dtXt83e3h4vvvgirl+/josXLwIAmjVrhhs3btQ5HdasWTMcP34ct27dqvf75+XlAQCUSuV9foJ7mzJlSo1t48aNw+nTp3H16lXdtk2bNkGhUGDUqFEAgKioKFy+fBnjx49HZmYmMjIykJGRgcLCQgwePBiRkZFmuwCciOWGyEx4eXnBysqqxvYLFy7g8ccfh4ODA1QqFVxdXXWLkXNzc+/5uj4+PtV+rio6d64LuV8JCQlo165dje1VZ35VrUv5z3/+A3t7ewQFBaFNmzaYOnVqjXUnH3zwAaKjo+Ht7Y2goCC89dZb9yxgKpUKQGXpayx+fn41to0ZMwYymQybNm0CAIiiiC1btiAsLEyX6fLlywCASZMmwdXVtdrjs88+Q2lpab1+f0SmiOWGyEzcOUJTJScnBwMGDMC5c+fw9ttv45dffsG+ffvw/vvvA0C9/stfLpfXul0UxQcL3AAdOnRAbGwsfvjhB/Tt2xfbtm1D3759sWDBAt0+Y8eORXx8PFauXAlPT08sXboU/v7+2LVr111fV6VSwdPTE9HR0fXKIQhCrdv/uTj7TrX9Xjw9PdGvXz9s3rwZQOUZcImJiRg3bpxun6rfzdKlS7Fv375aH/b29vXKTWRquKCYyIwdPHgQmZmZ+PHHH9G/f3/d9mvXrkmY6m8tWrRAbGxsje1V02UtWrTQbbOzs8O4ceMwbtw4lJWV4YknnsCiRYswd+5cWFtbAwA8PDzwyiuv4JVXXkFaWhq6deuGRYsWISws7K4ZHnnkEaxfvx5Hjx5F796968xbNWqVk5NTbXttZz7dy7hx4/DKK68gNjYWmzZtgq2tLUaOHKl7vlWrVgAqC1hoaGiDX5/IlHHkhsiMVY263DnKUlZWhjVr1kgVqZrhw4fjxIkTOHr0qG5bYWEh1q9fD19fX3Ts2BFA5Zlgd7KyskLHjh0hiiLKy8uh0WhqTNG4ubnB09MTpaWldWZ44403YGdnhxdeeAGpqak1nr969So++eQTAJVFw8XFBZGRkdX2uZ+/z9GjR0Mul+P777/Hli1b8Mgjj1S7Bk737t3RqlUrfPjhhygoKKhxfHp6eoPfk8hUcOSGyIz16dMHjo6OmDRpEmbMmAFBEPDNN9806ZTStm3bal24PGnSJMyZMwfff/89wsLCMGPGDDg5OeGrr77CtWvXsG3bNshklf99NnToULi7uyMkJARqtRoxMTFYtWoVRowYAaVSiZycHDRv3hxPPvkkAgICYG9vj/379+PkyZNYtmxZnflatWqFjRs3Yty4cejQoUO1KxT/+eef2LJlC5577jnd/i+88ALee+89vPDCC+jRowciIyMRFxfX4L8XNzc3DBo0CB999BHy8/OrTUkBgEwmw2effYawsDD4+/tj8uTJ8PLyws2bN3HgwAGoVCr88ssvDX5fIpMg6blaRKR3dzsV/G6nSh85ckTs1auXaGNjI3p6eopvvPGGuGfPHhGAeODAAd1+dzsVfOnSpTVeE/847bk2VaeC3+1Rdfr31atXxSeffFJs1qyZaG1tLQYFBYm//vprtdf69NNPxf79+4vOzs6iQqEQW7VqJb7++utibm6uKIqiWFpaKr7++utiQECAqFQqRTs7OzEgIEBcs2ZNnRnvFBcXJ/773/8WfX19RSsrK1GpVIohISHiypUrq50yX1RUJP7rX/8SHRwcRKVSKY4dO1ZMS0u766ng6enpd33PDRs2iABEpVIpFhcX17rP2bNnxSeeeEL32Vu0aCGOHTtWjIiIqPdnIzI1gig24X+iERERETUyrrkhIiIik8JyQ0RERCaF5YaIiIhMCssNERERmRSWGyIiIjIpLDdERERkUszuIn5arRa3bt2CUqm8631giIiIyLCIooj8/Hx4enrqLuB5N2ZXbm7dugVvb2+pYxAREdF9SEpKQvPmzevcx+zKjVKpBFD5l6NSqSROQ0RERPWRl5cHb29v3fd4Xcyu3FRNRalUKpYbIiIiI1OfJSVcUExEREQmheWGiIiITArLDREREZkUlhsiIiIyKSw3REREZFJYboiIiMiksNwQERGRSWG5ISIiIpPCckNEREQmheWGiIiITArLDREREZkUlhsiIiIyKSw3epRRUIqY5DypYxAREZk1lhs92R2dgqBF+zH3x/NSRyEiIjJrLDd60q1FM4gAopJycCunWOo4REREZovlRk/clNbo0cIRQOUoDhEREUmD5UaPHu7kAYDlhoiISEqSlpvIyEiMHDkSnp6eEAQBO3bsqPexR44cgYWFBbp27dpo+Rrq4U7uAICTCVlIyy+ROA0REZF5krTcFBYWIiAgAKtXr27QcTk5OZg4cSIGDx7cSMnuj1czGwR4N4MoAnsvpEodh4iIyCxZSPnmYWFhCAsLa/BxU6ZMwfjx4yGXyxs02tMUwjq541xSDnZFJ+OZXi2kjkNERGR2jG7NzRdffIH4+HgsWLCgXvuXlpYiLy+v2qMxhd2emjoWn4XswrJGfS8iIiKqyajKzeXLlzFnzhx8++23sLCo36DTkiVL4ODgoHt4e3s3asYWznbo6KGCRiti30VOTRERETU1oyk3Go0G48ePx8KFC9G2bdt6Hzd37lzk5ubqHklJSY2YslLV6M2u6ORGfy8iIiKqTtI1Nw2Rn5+PU6dO4ezZs5g2bRoAQKvVQhRFWFhYYO/evXjooYdqHKdQKKBQKJo0a1hndyzbF4fDVzKQW1wOBxvLJn1/IiIic2Y05UalUuH8+eq3NlizZg1+//13bN26FX5+fhIlq6m1mxKt3exxJa0Av19KxeOBzaWOREREZDYkLTcFBQW4cuWK7udr164hKioKTk5O8PHxwdy5c3Hz5k18/fXXkMlk6NSpU7Xj3dzcYG1tXWO7IRjeyR0rfr+CXedTWG6IiIiakKRrbk6dOoXAwEAEBgYCAMLDwxEYGIj58+cDAJKTk5GYmChlxPtWdbXiP+LSUVhaIXEaIiIi8yGIoihKHaIp5eXlwcHBAbm5uVCpVI32PqIoYuCHB5GQWYRV4wPxSBfPRnsvIiIiU9eQ72+jOVvK2AiCoLsdwy7ea4qIiKjJsNw0ouG3p6YOXEpDSblG4jRERETmgeWmEXVp7gCvZjYoKtMgMi5d6jhERERmgeWmEQmCgGH+nJoiIiJqSiw3jWx458pysz8mFWUVWonTEBERmT6Wm0bWzccRbkoF8ksqcORqhtRxiIiITB7LTSOTyf6emtp9nlNTREREjY3lpglU3Uhz78UUVGg4NUVERNSYWG6aQJCfE5zsrJBdVI7j17KkjkNERGTSWG6agIVchqEd1QCAXdHJEqchIiIybSw3TaTqasV7LqRCozWrO14QERE1KZabJtKnlQuU1hZIzy/F6YRsqeMQERGZLJabJmJlIcMQTk0RERE1OpabJhR2+15Tu6NToOXUFBERUaNguWlC/dq4wM5KjuTcEpy7kSN1HCIiIpPEctOErC3lGNTeDUDl6A0RERHpH8tNExveuXJqald0CkSRU1NERET6xnLTxAa2c4W1pQyJWUW4mJwndRwiIiKTw3LTxGytLDCgrSsAYBfvNUVERKR3LDcSqDpriqeEExER6R/LjQQe6uAGK7kMV9MLcTk1X+o4REREJoXlRgIqa0v0beMCoHJhMREREekPy41Equ41tfM8p6aIiIj0ieVGIkM6qCGXCbiUko/rGYVSxyEiIjIZLDcScbSzQp9WzgA4NUVERKRPLDcSqpqa2s2zpoiIiPSG5UZCQzu6QxCAczdycSO7SOo4REREJoHlRkKuSgV6+joB4L2miIiI9IXlRmLDdVNTLDdERET6wHIjsYdvX634dGI2UvNKJE5DRERk/FhuJObuYI1An2YQRWDPBY7eEBERPSiWGwMwvOpeU7yRJhER0QNjuTEAVaeEH7+WicyCUonTEBERGTeWGwPg7WSLTl4qaEVg38VUqeMQEREZNZYbAxF2e2pqJ8+aIiIieiAsNwYi7PbU1J9XMpBbVC5xGiIiIuPFcmMgWrrao51aiQqtiP0xnJoiIiK6Xyw3BqRqYTFvpElERHT/WG4MSFjnynITeTkdBaUVEqchIiIyTiw3BqSdWomWLnYoq9Di90tpUschIiIySiw3BkQQBN3U1O7oZInTEBERGSeWGwNTdUr4gUvpKC7TSJyGiIjI+EhabiIjIzFy5Eh4enpCEATs2LGjzv1//PFHDBkyBK6urlCpVOjduzf27NnTNGGbSCcvFZo72qC4XIM/4jg1RURE1FCSlpvCwkIEBARg9erV9do/MjISQ4YMwc6dO3H69GkMGjQII0eOxNmzZxs5adMRBEF3zRueNUVERNRwgiiKotQhgMov9e3bt+Oxxx5r0HH+/v4YN24c5s+fX6/98/Ly4ODggNzcXKhUqvtI2vhOJ2Rj9No/Ya+wwOl5oVBYyKWOREREJKmGfH8b9ZobrVaL/Px8ODk53XWf0tJS5OXlVXsYukDvZlCrFCgorcDhyxlSxyEiIjIqRl1uPvzwQxQUFGDs2LF33WfJkiVwcHDQPby9vZsw4f2RyQQ87M+pKSIiovthtOVm48aNWLhwITZv3gw3N7e77jd37lzk5ubqHklJSU2Y8v6Fda48a2rfxVSUa7QSpyEiIjIeFlIHuB8//PADXnjhBWzZsgWhoaF17qtQKKBQKJoomf709HWCi70VMgrKcCw+E/3auEodiYiIyCgY3cjN999/j8mTJ+P777/HiBEjpI7TaOQyAUM6Vk5N7TzPqSkiIqL6krTcFBQUICoqClFRUQCAa9euISoqComJiQAqp5QmTpyo23/jxo2YOHEili1bhuDgYKSkpCAlJQW5ublSxG90VaeE77uYAo3WIE5qIyIiMniSlptTp04hMDAQgYGBAIDw8HAEBgbqTutOTk7WFR0AWL9+PSoqKjB16lR4eHjoHjNnzpQkf2Pr3coZDjaWyCgow8nrWVLHISIiMgoGc52bpmIM17m502tbzmHr6Rt4ro8v3nrUX+o4REREkjCb69yYg7+vVpwMLaemiIiI7onlxsD1beMCe4UFUvNKcTYpR+o4REREBo/lxsApLOQY3KHyOj67o5MlTkNERGT4WG6MwJ030jSzJVJEREQNxnJjBAa0dYONpRw3sosRfdPw741FREQkJZYbI2BjJcfAdpVXKN7FqSkiIqI6sdwYiap7Te3m1BQREVGdWG6MxEPt3WBlIUN8RiHiUgukjkNERGSwWG6MhL3CAv3buAAAdp7n1BQREdHdsNwYkbBOf09NERERUe1YboxIaAc1LGQCYlPzEZ/OqSkiIqLasNwYEQdbS/RpXTk1tYujN0RERLViuTEyd95rioiIiGpiuTEyQzuqIROA6Jt5SMoqkjoOERGRwWG5MTLO9goE+zkD4MJiIiKi2rDcGKGwzpyaIiIiuhuWGyM0zL+y3JxJzEFybrHEaYiIiAwLy40RUqus0aOFIwBgD6emiIiIqmG5MVIP686aYrkhIiK6E8uNkaoqNyeuZyE9v1TiNERERIaD5cZINXe0RZfmDhBFYO9Fjt4QERFVYbkxYrzXFBERUU0sN0as6mrFf17NRHZhmcRpiIiIDAPLjRHzdbFDe3clNFoR+2JSpY5DRERkEFhujBynpoiIiKpjuTFyw29frfjw5Qzkl5RLnIaIiEh6LDdGro1aiVaudijTaPH7pTSp4xAREUmO5cYEVE1N7TzPe00RERGx3JiAqgv6/RGXjqKyConTEBERSYvlxgT4e6rg42SLknItDsamSx2HiIhIUiw3JkAQBN01b3ivKSIiMncsNyaiamrq95hUlJRrJE5DREQkHZYbExHQvBk8HKxRWKbBocsZUschIiKSDMuNiZDJBN3oza5onjVFRETmi+XGhFSdEr7/YirKKrQSpyEiIpIGy40J6d7CES72CuSVVODPq5yaIiIi88RyY0LkMgEPd1ID4L2miIjIfLHcmJiqqam9F1NRoeHUFBERmR+WGxMT7OcER1tLZBWW4cT1LKnjEBERNTmWGxNjIZdhSMfKqald5zk1RURE5oflxgSFda6cmtpzIQVarShxGiIioqbFcmOCQlq5QGltgbT8UpxJzJY6DhERUZOStNxERkZi5MiR8PT0hCAI2LFjxz2POXjwILp16waFQoHWrVvjyy+/bPScxsbKQobQDrenpnjWFBERmRlJy01hYSECAgKwevXqeu1/7do1jBgxAoMGDUJUVBRmzZqFF154AXv27GnkpMan6mrFu6NTIIqcmiIiIvNhIeWbh4WFISwsrN77r1u3Dn5+fli2bBkAoEOHDjh8+DA+/vhjDBs2rLFiGqUBbV1hayXHzZxi/HUjFwHezaSORERE1CSMas3N0aNHERoaWm3bsGHDcPTo0bseU1pairy8vGoPc2BtKceg9m4AODVFRETmxajKTUpKCtRqdbVtarUaeXl5KC4urvWYJUuWwMHBQffw9vZuiqgGIUw3NZXMqSkiIjIbRlVu7sfcuXORm5ureyQlJUkdqckMaucGhYUM1zOLEJOcL3UcIiKiJmFU5cbd3R2pqanVtqWmpkKlUsHGxqbWYxQKBVQqVbWHubBTWGBAW1cAlaM3RERE5sCoyk3v3r0RERFRbdu+ffvQu3dviRIZvrDOlVNTXHdDRETmQtJyU1BQgKioKERFRQGoPNU7KioKiYmJACqnlCZOnKjbf8qUKYiPj8cbb7yBS5cuYc2aNdi8eTNmz54tRXyj8FB7NSzlAi6nFeBKGqemiIjI9Elabk6dOoXAwEAEBgYCAMLDwxEYGIj58+cDAJKTk3VFBwD8/Pzw22+/Yd++fQgICMCyZcvw2Wef8TTwOjjYWCKktQsA3muKiIjMgyCa2Wk0eXl5cHBwQG5urtmsv9l8MglvbPsLHT1U2Dmzn9RxiIiIGqwh399GteaG7s+QjmrIZQIuJuchIbNQ6jhERESNiuXGDDjaWaFXSycAXFhMRESmj+XGTDzcyQMAyw0REZk+lhszMcxfDUEAziXl4FZO7VdzJiIiMgUsN2bCTWmNni0qp6Z2c/SGiIhMGMuNGXm4U9UF/Xi1YiIiMl0sN2akqtycSshGWn6JxGmIiIgaB8uNGfFsZoOu3s0gisCeC6n3PoCIiMgIsdyYmbDboze8kSYREZkqlhszE3b7lPBj8VnIKiyTOA0REZH+sdyYGR9nW3T0UEGjFbHvIs+aIiIi08NyY4aGd646a4rlhoiITA/LjRmqulrxkSsZyC0ulzgNERGRfrHcmKHWbvZo42aPco2IiBieNUVERKaF5cZMhXXmvaaIiMg0NbjcFBcXo6ioSPdzQkICli9fjr179+o1GDWuqlPCI+PSUVhaIXEaIiIi/WlwuRk1ahS+/vprAEBOTg6Cg4OxbNkyjBo1CmvXrtV7QGoc7d2V8HW2RWmFFgdi06SOQ0REpDcNLjdnzpxBv379AABbt26FWq1GQkICvv76a6xYsULvAalxCIKgW1i86zynpoiIyHQ0uNwUFRVBqVQCAPbu3YsnnngCMpkMvXr1QkJCgt4DUuOpOiX8QGwaSso1EqchIiLSjwaXm9atW2PHjh1ISkrCnj17MHToUABAWloaVCqV3gNS4+ns5QCvZjYoKtPgj7h0qeMQERHpRYPLzfz58/Haa6/B19cXwcHB6N27N4DKUZzAwEC9B6TGUzk1VXWvKU5NERGRaWhwuXnyySeRmJiIU6dOYffu3brtgwcPxscff6zXcNT4qs6a2n8xFaUVnJoiIiLjd1/XuXF3d0dgYCBkMhny8vKwY8cOKJVKtG/fXt/5qJF183GEm1KB/NIK/HklU+o4RERED6zB5Wbs2LFYtWoVgMpr3vTo0QNjx45Fly5dsG3bNr0HpMYlk/09NbUrOlniNERERA+uweUmMjJSdyr49u3bIYoicnJysGLFCrz77rt6D0iNr6rc7L2YinKNVuI0RERED6bB5SY3NxdOTk4AgN27d2P06NGwtbXFiBEjcPnyZb0HpMYX5OsEJzsr5BSV43h8ltRxiIiIHkiDy423tzeOHj2KwsJC7N69W3cqeHZ2NqytrfUekBqfhVyGYf5qAJyaIiIi49fgcjNr1ixMmDABzZs3h6enJwYOHAigcrqqc+fO+s5HTaTqasV7LqRCoxUlTkNERHT/LBp6wCuvvIKgoCAkJSVhyJAhkMkq+1HLli255saI9W7pDJW1BTIKSnHqehaCWzpLHYmIiOi+NLjcAECPHj3Qo0cPiKIIURQhCAJGjBih72zUhKwsZAjtqMaPZ25iV3QKyw0RERmt+7rOzddff43OnTvDxsYGNjY26NKlC7755ht9Z6MmNlw3NZUCLaemiIjISDV45Oajjz7CvHnzMG3aNISEhAAADh8+jClTpiAjIwOzZ8/We0hqGn3buMDOSo7k3BKcu5GDQB9HqSMRERE1WIPLzcqVK7F27VpMnDhRt+3RRx+Fv78/3nrrLZYbI2ZtKcdDHdT45dwt7IpOYbkhIiKj1OBpqeTkZPTp06fG9j59+iA5macRG7uqe039cu4WCksrJE5DRETUcA0uN61bt8bmzZtrbN+0aRPatGmjl1AknUHt3KBWKZCcW4I3d0RDFLn2hoiIjEuDp6UWLlyIcePGITIyUrfm5siRI4iIiKi19JBxsbGSY8VTgRj/2XFsP3sTQX5OeDrIR+pYRERE9dbgkZvRo0fj+PHjcHFxwY4dO7Bjxw64uLjgxIkTePzxxxsjIzWx4JbOeG1oOwDAgp8vIPpmrsSJiIiI6k8Q9TTvkJaWhs8++wz//e9/9fFyjSYvLw8ODg7Izc2FSqWSOo7B0mpF/PvrU4i4lIYWzrb4ZXpfqKwtpY5FRERmqiHf3/d1nZvaJCcnY968efp6OZKYTCZg2dgAeDWzQUJmEd7Y8hfX3xARkVHQW7kh09PM1gqrJ3SDpVzA7gsp+L8j16WOREREdE8sN1Snrt7N8L/hHQAAS3bG4ExitsSJiIiI6iZ5uVm9ejV8fX1hbW2N4OBgnDhxos79ly9fjnbt2sHGxgbe3t6YPXs2SkpKmiiteZrUxxcjOnugQiti2ndnkF1YJnUkIiKiu6r3qeDh4eF1Pp+ent7gN9+0aRPCw8Oxbt06BAcHY/ny5Rg2bBhiY2Ph5uZWY/+NGzdizpw5+L//+z/06dMHcXFxeO655yAIAj766KMGvz/VjyAIeG90Z1xMzsO1jELM3hyF/5vUEzKZIHU0IiKiGup9ttSgQYPq9YIHDhyo95sHBwejZ8+eWLVqFQBAq9XC29sb06dPx5w5c2rsP23aNMTExCAiIkK37dVXX8Xx48dx+PDher0nz5a6fzHJeXhs9RGUVmjx+rB2mDqotdSRiIjITDTk+7veIzcNKS31UVZWhtOnT2Pu3Lm6bTKZDKGhoTh69Gitx/Tp0wfffvstTpw4gaCgIMTHx2Pnzp149tln9ZqNatfBQ4V3RnXCG9v+wrK9sejm44jerZyljkVERFRNg69QrC8ZGRnQaDRQq9XVtqvValy6dKnWY8aPH4+MjAz07dsXoiiioqICU6ZMqfPaOqWlpSgtLdX9nJeXp58PYKbG9GiO49eysO3MDUz//ix2zuwLN6W11LGIiIh0JF9Q3BAHDx7E4sWLsWbNGpw5cwY//vgjfvvtN7zzzjt3PWbJkiVwcHDQPby9vZswsekRBAHvPtYJ7dRKZBSUYsb3Z6HR8vo3RERkOCQrNy4uLpDL5UhNTa22PTU1Fe7u7rUeM2/ePDz77LN44YUX0LlzZzz++ONYvHgxlixZAq1WW+sxc+fORW5uru6RlJSk989ibmys5Fg9oRvsrOQ4Fp+Fj/fFSR2JiIhIR7JyY2Vlhe7du1dbHKzVahEREYHevXvXekxRURFksuqR5XI5ANz16rkKhQIqlaragx5cazd7LH6iMwBg1YErOBCbJnEiIiKiSpJOS4WHh2PDhg346quvEBMTg5dffhmFhYWYPHkyAGDixInVFhyPHDkSa9euxQ8//IBr165h3759mDdvHkaOHKkrOdR0RnX1wjO9Ku8YHr4pCrdyiiVOREREdJ8LinNycnDixAmkpaXVmA6aOHFivV9n3LhxSE9Px/z585GSkoKuXbti9+7dukXGiYmJ1UZq3nzzTQiCgDfffBM3b96Eq6srRo4ciUWLFt3PxyA9mPdIR5xLysX5m7mYuvEMNr3YG1YWRrWUi4iITEyD7wr+yy+/YMKECSgoKIBKpYIg/H0hN0EQkJWVpfeQ+sTr3OhfYmYRRqw8hPySCvyrrx/mPdJR6khERGRiGvWu4K+++iqef/55FBQUICcnB9nZ2bqHoRcbahw+zrZYNiYAAPD54WvYHZ0scSIiIjJnDS43N2/exIwZM2Bra9sYechIDfV3x4v9WwIAXt/yFxIyCyVORERE5qrB5WbYsGE4depUY2QhI/f6sHbo0cIR+aUVeOW7Mygp10gdiYiIzFCDFxSPGDECr7/+Oi5evIjOnTvD0tKy2vOPPvqo3sKRcbGUy7ByfCBGrDiMC7fy8PavF7H48c5SxyIiIjPT4AXF/7zOTLUXEwRoNIb9X+tcUNz4IuPSMemLExBFYPm4rngs0EvqSEREZOQadUGxVqu968PQiw01jf5tXTH9oTYAgLk/nsfl1HyJExERkTnhBUmoUcwc3AYhrZ1RXK7BK9+dQVFZhdSRiIjITNRrzc2KFSvw4osvwtraGitWrKhz3xkzZuglGBk3uUzA8nGBGLHiEC6nFeDN7dFYNjag2nWRiIiIGkO91tz4+fnh1KlTcHZ2hp+f391fTBAQHx+v14D6xjU3Tet4fCbGf3YcGq2IJU90xtNBPlJHIiIiI9SQ7+8GLyg2diw3TW/twat4f/clWFnI8OPLfdDJy0HqSEREZGQadUExUUO91L8lBrd3Q1mFFlM3nkFeSbnUkYiIyITd140zb9y4gZ9//hmJiYkoKyur9txHH32kl2BkOmQyAcvGBmDEisNIyCzCG1v+wtpnunH9DRERNYoGl5uIiAg8+uijaNmyJS5duoROnTrh+vXrEEUR3bp1a4yMZAKa2Vph9YRuGLPuT+y+kIIvjlzH833vvn6LiIjofjV4Wmru3Ll47bXXcP78eVhbW2Pbtm1ISkrCgAEDMGbMmMbISCaiq3cz/G94BwDA4p0xOJOYLXEiIiIyRQ0uNzExMZg4cSIAwMLCAsXFxbC3t8fbb7+N999/X+8BybRM6uOLEZ09UKEVMe27M8guLLv3QURERA3Q4HJjZ2enW2fj4eGBq1ev6p7LyMjQXzIySYIg4L3RneHnYodbuSWYvTkKWq1ZnbBHRESNrMHlplevXjh8+DAAYPjw4Xj11VexaNEiPP/88+jVq5feA5LpUVpbYvX4blBYyHAwNh1r/7h674OIiIjqqcHl5qOPPkJwcDAAYOHChRg8eDA2bdoEX19ffP7553oPSKapo6cKb4/yBwAs2xuLo1czJU5ERESmokEX8dNoNDhy5Ai6dOmCZs2aNWKsxsOL+BkOURTx2pa/sO3MDbgqFfhtRl+4Ka2ljkVERAao0S7iJ5fLMXToUGRn8ywXenCCIOCdx/zRVm2P9PxSzPw+ChquvyEiogfU4GmpTp06Gfz9o8h42FpZYM2E7rC1kuNofCY+3hcndSQiIjJyDS437777Ll577TX8+uuvSE5ORl5eXrUHUUO1drPHkic6AwBWHbiCA7FpEiciIiJjVu81N2+//TZeffVVKJXKvw++4/L5oihCEARoNBr9p9QjrrkxXG/uOI9vjyXC0dYSv83oB89mNlJHIiIiA9EodwWXy+VITk5GTExMnfsNGDCg/kklwHJjuErKNXhy3Z+IvpmHQJ9m2PRib1hZ8N6uRETUSOVGJpMhJSUFbm5uegkpFZYbw5aYWYQRKw8hv6QC/+rrh3mPdJQ6EhERGYBGO1uKd3GmxubjbIsPxwQAAD4/fA27o1MkTkRERMamQXcFb9u27T0LTlZW1gMFIhrm745/9/PDhkPX8PqWc+jgoUQLZzupYxERkZFoULlZuHAhHBwcGisLkc4bD7fHmcQcnE7IxivfncG2l/vA2lIudSwiIjICXHNDBis5txgjVhxGVmEZxgf7YPHjnaWOREREEmmUNTdcb0NNzcPBBsvHdYUgABuPJ2LH2ZtSRyIiIiNQ73LTgFtQEelN/7aumD6oNQDgv9vP40pavsSJiIjI0NW73Gi1WqOfkiLjNDO0Lfq0ckZRmQYvf3sGRWUVUkciIiIDxiukkcGTywR88lQg3JQKXE4rwJvbozmSSEREd8VyQ0bBVanAyqcDIROAH8/exA8nk6SOREREBorlhoxGcEtnvDasHQBgwc8XcOFWrsSJiIjIELHckFGZ0r8VHmrvhrIKLV757gzySsqljkRERAaG5YaMikwmYNmYAHg1s0FCZhH+s/Uvrr8hIqJqWG7I6DjaWWH1hG6wlAvYFZ2CL45clzoSEREZEJYbMkpdvZvhf8M7AAAW74zBmcRsiRMREZGhYLkhozWpjy9GdPZAhVbEtO/OILuwTOpIRERkAFhuyGgJgoD3RneGr7MtbuWWIHxzFLRarr8hIjJ3LDdk1JTWllgzoTsUFjIciE3H2j+uSh2JiIgkJnm5Wb16NXx9fWFtbY3g4GCcOHGizv1zcnIwdepUeHh4QKFQoG3btti5c2cTpSVD1NFThbdH+QMAlu2NxbH4TIkTERGRlCQtN5s2bUJ4eDgWLFiAM2fOICAgAMOGDUNaWlqt+5eVlWHIkCG4fv06tm7ditjYWGzYsAFeXl5NnJwMzdge3niimxe0IjD9+7NIyy+ROhIREUlEECW8SEhwcDB69uyJVatWAai8Oae3tzemT5+OOXPm1Nh/3bp1WLp0KS5dugRLS8v7es+8vDw4ODggNzcXKpXqgfKTYSkqq8Bjq48gLrUAvVs649sXgiGXCVLHIiIiPWjI97dkIzdlZWU4ffo0QkND/w4jkyE0NBRHjx6t9Ziff/4ZvXv3xtSpU6FWq9GpUycsXrwYGo2mqWKTAbO1ssCaCd1gayXH0fhMLN8fJ3UkIiKSgGTlJiMjAxqNBmq1utp2tVqNlJSUWo+Jj4/H1q1bodFosHPnTsybNw/Lli3Du+++e9f3KS0tRV5eXrUHma7WbkoseaIzAGDl71dwMLb2KU4iIjJdki8obgitVgs3NzesX78e3bt3x7hx4/C///0P69atu+sxS5YsgYODg+7h7e3dhIlJCqO6emFCsA8AYPrGs9h+9gZv0UBEZEYkKzcuLi6Qy+VITU2ttj01NRXu7u61HuPh4YG2bdtCLpfrtnXo0AEpKSkoK6v9Am5z585Fbm6u7pGUlKS/D0EGa94jHRHk54T80grM3nQOL397BpkFpVLHIiKiJiBZubGyskL37t0RERGh26bVahEREYHevXvXekxISAiuXLkCrVar2xYXFwcPDw9YWVnVeoxCoYBKpar2INNnbSnHxheC8eqQtrCQCdh9IQVDP47Engu1T3kSEZHpkHRaKjw8HBs2bMBXX32FmJgYvPzyyygsLMTkyZMBABMnTsTcuXN1+7/88svIysrCzJkzERcXh99++w2LFy/G1KlTpfoIZMAs5DJMH9wGP00LQTu1EpmFZXjpm9MI3xSF3OJyqeMREVEjsZDyzceNG4f09HTMnz8fKSkp6Nq1K3bv3q1bZJyYmAiZ7O/+5e3tjT179mD27Nno0qULvLy8MHPmTPznP/+R6iOQEfD3dMDP00OwfP9lfPrHVfx49ib+vJqJD57sgv5tXaWOR0REeibpdW6kwOvcmLfTCVl4dfM5XM8sAgA808sHc8M6wE4hac8nIqJ7MIrr3BBJoXsLJ+yc2Q+TercAAHx7LBHDVxzCyetZEicjIiJ9Ybkhs2NrZYGFozrhuxeC4elgjYTMIoz99CiW7IxBSTkvCElEZOxYbshshbR2we7Z/fFk9+YQReDTyHg8uuowom/mSh2NiIgeAMsNmTWVtSU+HBOADRN7wMVegbjUAjy2+giW749DuUZ77xcgIiKDw3JDBGBIRzX2zu6P4Z3dUaEVsXz/ZTyx5k9cTs2XOhoRETUQyw3RbU52Vlg9vhs+eaorHGwscf5mLkasPIwNkfHQaM3qpEIiIqPGckN0B0EQMKqrF/bO7o+B7VxRVqHFop0xeHr9MSTePn2ciIgMG8sNUS3UKmt88VxPvPdEZ9hZyXHiehYe/iQS3x1P4E04iYgMHMsN0V0IgoCngnywe1Z/BPs5oahMg/9tj8akL04iJbdE6nhERHQXLDdE9+DtZIvv/90Lb47oACsLGSLj0jH04z+w/ewNjuIQERkglhuiepDJBLzQryV2zuiLgOYOyCupwOxN5/Dyt2eQWVAqdTwiIroDyw1RA7R2U2Lby33w6pC2sJAJ2H0hBUM/jsSeCylSRyMiottYbogayEIuw/TBbbBjagjaqZXILCzDS9+cRvjmKOQWl0sdj4jI7LHcEN2nTl4O+Hl6CKYMaAWZAPx45iYeXh6JQ5fTpY5GRGTWWG6IHoDCQo45Ye2xZUpv+DrbIjm3BM9+fgJv7jiPorIKqeMREZkllhsiPejewgk7Z/bDpN4tAADfHktE2CeHcOp6lsTJiIjMD8sNkZ7YWllg4ahO+PZfwfB0sEZCZhHGfHoUS3bGoKRcI3U8IiKzwXJDpGd927hg9+z+eLJ7c4gi8GlkPB5ddRjRN3OljkZEZBZYbogagcraEh+OCcCGiT3gYm+FuNQCPLb6CD7ZfxnlGq3U8YiITBrLDVEjGtJRjb2zB2B4Z3dUaEV8vD8Oo9f+icup+VJHIyIyWSw3RI3Myc4Kq8d3wydPdYWDjSX+upGLESsP47ND8dBoefsGIiJ9Y7khagKCIGBUVy/snd0fA9q6oqxCi3d/i8HT648hMbNI6nhERCaF5YaoCalV1vhyck8seaIz7KzkOHE9Cw9/EonvjifwJpxERHrCckPUxARBwNNBPtg9qz+C/JxQVKbB/7ZH47kvTiIlt0TqeERERo/lhkgi3k62+OHfvfDmiA6wspDhj7h0DP34D+w4e5OjOERED4DlhkhCMpmAF/q1xM4ZfRHQ3AF5JRWYtSkKr3x3BpkFpVLHIyIySiw3RAagtZsS217ug1eHtIWFTMCu6BQMWx6JvRdSpI5GRGR0WG6IDISFXIbpg9tgx9QQtFMrkVFQhhe/OY3wzVHILS6XOh4RkdEQRDOb3M/Ly4ODgwNyc3OhUqmkjkNUq9IKDT7edxnrI69CKwKOtpYI7aDG4A5q9GvjAjuFhdQRiYiaVEO+v1luiAzY6YQsvLr5HK7fcS0cK7kMvVo5I7SDGwZ3UMOrmY2ECYmImgbLTR1YbsjYlGu0OHEtCxExaYi4lIqEf1z0r727EqEd1Hiogxu6Nm8GmUyQKCkRUeNhuakDyw0ZM1EUcTW9APtj0hARk4rTCdm48w4OLvZWGNTOjdNXRGRyWG7qwHJDpiS7sAwH49KwPyYNkbHpyC+t0D3H6SsiMiUsN3VguSFTVVahxcnrWdgfk4qImDQkZnH6iohMB8tNHVhuyBxw+oqITA3LTR1YbsgccfqKiIwdy00dWG7I3HH6ioiMEctNHVhuiP7G6SsiMhYsN3VguSG6u6zCMvzB6SsiMkAsN3VguSGqH05fEZEhYbmpA8sNUcNx+oqIpMZyUweWG6IHl1VYhoOxaYi4xOkrImoaRlduVq9ejaVLlyIlJQUBAQFYuXIlgoKC7nncDz/8gKeffhqjRo3Cjh076vVeLDdE+sXpKyJqCkZVbjZt2oSJEydi3bp1CA4OxvLly7FlyxbExsbCzc3trsddv34dffv2RcuWLeHk5MRyQ2QA7jV95a6yxssDW+GpIG8oLOTSBSUio2NU5SY4OBg9e/bEqlWrAABarRbe3t6YPn065syZU+sxGo0G/fv3x/PPP49Dhw4hJyeH5YbIAN1t+srTwRrTB7fBk92bw1IukzglERmDhnx/S/pvlbKyMpw+fRqhoaG6bTKZDKGhoTh69Ohdj3v77bfh5uaGf/3rX00Rk4juk5OdFZ7o1hyrx3fDqXmhWPR4J7irrHErtwRzfzyPwcv+wI9nbkCjlXx2nIhMiKSnNGRkZECj0UCtVlfbrlarcenSpVqPOXz4MD7//HNERUXV6z1KS0tRWlqq+zkvL+++8xLR/VNYyDEhuAVGd2uOjccTsebgFSRmFSF88zmsPnAFs4e0xfBOHlyTQ0QPzKjGg/Pz8/Hss89iw4YNcHFxqdcxS5YsgYODg+7h7e3dyCmJqC7WlnI839cPkW8Mwpyw9mhma4mr6YWYtvEshq84hH0XU2EA5zkQkRGTdM1NWVkZbG1tsXXrVjz22GO67ZMmTUJOTg5++umnavtHRUUhMDAQcvnfCxG1Wi2Ayums2NhYtGrVqtoxtY3ceHt7c80NkYHILynH/x2+js8OxevW5AQ0d0D40Hbo38YFgsCRHCIywgXFQUFBWLlyJYDKsuLj44Np06bVWFBcUlKCK1euVNv25ptvIj8/H5988gnatm0LKyurOt+PC4qJDFNOURk2HIrHF0euo6hMAwDo6euIV4e2Q6+WzhKnIyKpNeT7W/LLiIaHh2PSpEno0aMHgoKCsHz5chQWFmLy5MkAgIkTJ8LLywtLliyBtbU1OnXqVO34Zs2aAUCN7URkXJrZWuH1Ye0xOcQP6w5exTfHEnDyejaeWn8MIa2d8erQdujm4yh1TCIyApKXm3HjxiE9PR3z589HSkoKunbtit27d+sWGScmJkImM6qlQUT0AFzsFXjzkY74d/+WWH3gCr4/kYgjVzJx5MqfeKi9G8KHtEUnLwepYxKRAZN8WqqpcVqKyLjcyC7Cyogr2HrHKeMP+7tj9pC2aOeulDgdETUVo1pz09RYboiM0/WMQnwScRk7om5CFAFBAB4N8MSs0Lbwc7GTOh4RNTKWmzqw3BAZt7jUfCzfH4ed51MAAHKZgNHdvDD9oTbwdrKVOB0RNRaWmzqw3BCZhuibufh4XxwiLqUBACzlAsb19Ma0QW3g7mAtcToi0jeWmzqw3BCZlrOJ2fhoXxwOXc4AAFhZyPBMcAu8PLAVXJUKidMRkb6w3NSB5YbINB2Lz8RHe+Nw4noWAMDGUo7nQnzxUv+WaGZb9/WviMjwsdzUgeWGyHSJoojDVzLw4d44nEvKAQAoFRZ4vq8f/tXPDyprS2kDEtF9Y7mpA8sNkekTRRERMWlYti8OMcmVN8t1sLHESwNa4rk+vrC1kvwSX0TUQCw3dWC5ITIfWq2IXdEp+Hh/HK6kFQAAXOyt8PLA1pgQ7ANrS/k9XoGIDAXLTR1YbojMj0Yr4udzN7F8/2UkZBYBANQqBaY91AbjenjDyoJXQScydCw3dWC5ITJf5RotfjxzAysiruBmTjEAwKuZDWaGtsETgV6wkLPkEBkqlps6sNwQUWmFBptOJmHV71eQll8KAPBzscOs0DZ4pIsn5DJB4oRE9E8sN3VguSGiKiXlGnx7LAFrDl5FVmEZAKCt2h7hQ9pimL87BIElh8hQsNzUgeWGiP6poLQCX/15HZ/+cRV5JRUAAH9PFV4d2haD2rmx5BAZAJabOrDcENHd5BaX4/PD1/D5oXgUlmkAAIE+zfDqkHYIae3MkkMkIZabOrDcENG9ZBWW4dPIq/jqz+soKdcCAIL9nPDasHbo6eskcToi88RyUweWGyKqr7T8Eqw5cBUbjyeiTFNZcvq3dcWMh1qjc3MHKCx4nRyipsJyUweWGyJqqFs5xVh14Ao2n0xChbbyX5mCALirrOHtaAtvJ1t4O9nAx8kWPk6VP7vaKyDjWVdEesNyUweWGyK6X4mZRfgk4jJ2RSej6PaanLtRWMjQ3NFGV3aq/reyDNlAyftcETUIy00dWG6I6EGJoojMwjIkZRUhMasIN7KLkZhZ+eek7CLcyimG9h7/ZnW0tYSPky2a3y4+PreLj4+TLTyaWcOSFxQkqqYh39+8exwRUQMJggAXewVc7BUI9HGs8Xy5RovknBJd2UmsKkG3/ze7qPz2IxfnbuTWOF4uE+DhYK0rOz7OttVGgZztrHjmFlEdWG6IiPTMUi6Dj3NlKalNfkk5krKKkZRdpBv9uXMUqLRCixvZxbiRXYyj8Zk1jre1kuvW+vjcsd6natrLxooLncm8sdwQETUxpbUlOnpaoqNnzaF1rVZEekGpruxUFp9iJN0eBUrJK0FRmQaxqfmITc2v9fVd7BXwcbKpsdbHx9kW7ipr3l6CTB7X3BARGZHSCg1uZhfrRnuSbq/3qZr+yr99heW7sZQL8GpWWXx8ne3Qr40L+rVx5WgPGTwuKK4Dyw0RmbLcovK/R3yy/57ySsoqws2cYpRrav4r39pShv5tXDHU3x2D27vB0c5KguREdWO5qQPLDRGZK41WREpeiW6k5+KtPOy7mIqbOcW6fWQCEOTnhCEd3TG0oxreTrWvGyJqaiw3dWC5ISL6myiKuJich70XUrH3YipikvOqPd/BQ4WhHdUY6q9GRw8Vz9IiybDc1IHlhojo7pKyirD3Yir2XUzBiWtZ1a7X49XMBkNuF50gXydY8Fo81IRYburAckNEVD9ZhWX4/VIa9l5IQeTldN1NRAGgma0lHmrvhqEd3dG/rQtsrXjyLTUulps6sNwQETVccZkGh69kYO+FFOyPSUV2UbnuOYWFDP3auGBoR3cM7uAGZ3uFhEnJVLHc1IHlhojowVRotDidkI29F1Ox92IKkrKqL0ju0cIJQ/3VGNJRjRbOdhImJVPCclMHlhsiIv0RRRGxqfm3FySnIPpm9QXJ7d2Vlet0OrqjkxcXJNP9Y7mpA8sNEVHjuZlTjH0XUrD3YiqOX8uC5o4VyZ4O1rcXJLsjyM+JNwelBmG5qQPLDRFR08gpKsOB2DTsvZCKg7HpKC7X6J5TWVtULkj2d8eAtq6wU3BBMtWN5aYOLDdERE2vpFyDI1cysPdCKvbHpCKzsEz3nJWFDH1bu2BoRzUGd1DDVckFyVQTy00dWG6IiKSl0Yo4m1i5IHnPhRQkZBbpnhMEoJuP4+0LB7rDz4ULkqkSy00dWG6IiAyHKIq4nFaAvbfX6fx1I7fa823c7G+feeWOLl4OkPGO5maL5aYOLDdERIYrObcY+y9W3gri6NVMVNyxIFmtUujOvOrV0hlWFlyQbE5YburAckNEZBxyi8txULcgOQ2FZX8vSFYqLDCovRuG+qsxoK0rlNaWEialpsByUweWGyIi41NaocGfVzOx90Iq9l1MRUZBqe45K7kMPf0cMbCtGwa2c0VrN3teT8cEsdzUgeWGiMi4abUiziblYN/FVOy9kIL4jMJqz3s1s8GAdq4Y2NYVIa1deJq5iWC5qQPLDRGRabmaXoCDsek4GJuG49eyUFbx9w0+LeUCgvycOKpjAlhu6sByQ0RkuorKKnAsPvN22UlHYlZRtec5qmO8jK7crF69GkuXLkVKSgoCAgKwcuVKBAUF1brvhg0b8PXXXyM6OhoA0L17dyxevPiu+/8Tyw0RkXkQRRHXMgori05cOo7FZ9YY1enp64SB7VwxsJ0b2nBUx6AZVbnZtGkTJk6ciHXr1iE4OBjLly/Hli1bEBsbCzc3txr7T5gwASEhIejTpw+sra3x/vvvY/v27bhw4QK8vLzu+X4sN0RE5qm4TINj8Zk4EJt211Gd/m1dMbBd5aiOPUd1DIpRlZvg4GD07NkTq1atAgBotVp4e3tj+vTpmDNnzj2P12g0cHR0xKpVqzBx4sR77s9yQ0RE9RnV6dHi71GdtmqO6kitId/fktbSsrIynD59GnPnztVtk8lkCA0NxdGjR+v1GkVFRSgvL4eTk1Otz5eWlqK09O9TBvPy8h4sNBERGT1BENDS1R4tXe3xfF8/3ajOwdg0HIxLR0JmEY7GZ+JofCaW7LoETwdrDGjnigFt3dC3DUd1DJ2kv52MjAxoNBqo1epq29VqNS5dulSv1/jPf/4DT09PhIaG1vr8kiVLsHDhwgfOSkREpsvGSo5B7d0wqH3lcojKUZ3K6atj8Zm4lVuC708k4fsTSbCQVV+rw1Edw2PU1fO9997DDz/8gIMHD8La2rrWfebOnYvw8HDdz3l5efD29m6qiEREZIT8XOzg5+KHySF+KCnX4Gh8Jv64fbr59X+M6ng4WGPg7VGdkNbOvFqyAZC03Li4uEAulyM1NbXa9tTUVLi7u9d57Icffoj33nsP+/fvR5cuXe66n0KhgEKh0EteIiIyP9aWcgxq54ZB7dwA+ON61ahOXDqOXs1E8j9GdXr4OmJgu8rr6rRTKzmqIwGDWFAcFBSElStXAqhcUOzj44Np06bddUHxBx98gEWLFmHPnj3o1atXg96PC4qJiEhfSso1d1xXp3JU504eDtYYcMcZWBzVuX9GdbbUpk2bMGnSJHz66acICgrC8uXLsXnzZly6dAlqtRoTJ06El5cXlixZAgB4//33MX/+fGzcuBEhISG617G3t4e9vf0934/lhoiIGss/R3VK7zgDy0ImoHuLv0d12rtzVKchjKrcAMCqVat0F/Hr2rUrVqxYgeDgYADAwIED4evriy+//BIA4Ovri4SEhBqvsWDBArz11lv3fC+WGyIiagp3jur8EZeOa/+4B5a76o5RnTYuUHFUp05GV26aEssNERFJISGzUDd9dTQ+EyXl1Ud1urVwRCtXe7jaW8FFqYCrvQIuSgVc7BVwsbeCvcLCrEd6WG7qwHJDRERSKynX4Pi1LByMTcMfsek17mxeG2tL2e2iU/lwVSp0RajqZ1MuQiw3dWC5ISIiQ5OQWYhj8ZVnXqXnlyKjoBQZBWXIKChFen4piso0DXo9hYXsjrJjGkXIaK5QTEREREALZzu0cLa76/NFZRXIyC9D+u2yU1l+SnXlp6oIZeSXorBMg9IKLW5kF+NGdvE937tmEbL6x5RYVRkyniLEckNERGTgbK0s4ONsAR9n23vue2cRyvhnGbpj+/0WoTtHflyVVv8YCaosQa5KhaSnvbPcEBERmZAHKULVylD+7WmxfxShmznFuJlTdxFq767E7ln99fWRGozlhoiIyEw1pAgVl2mQUVCKtBojQSW6IlRVjlyV0t4ZgOWGiIiI7snGSg5vJ1t4O927CJVrtPfcpzHJJH13IiIiMjmWcmnrBcsNERERmRSWGyIiIjIpLDdERERkUlhuiIiIyKSw3BAREZFJYbkhIiIik8JyQ0RERCaF5YaIiIhMCssNERERmRSWGyIiIjIpLDdERERkUlhuiIiIyKSw3BAREZFJsZA6QFMTRREAkJeXJ3ESIiIiqq+q7+2q7/G6mF25yc/PBwB4e3tLnISIiIgaKj8/Hw4ODnXuI4j1qUAmRKvV4tatW1AqlRAEQa+vnZeXB29vbyQlJUGlUun1tanh+PswLPx9GBb+PgwPfyd1E0UR+fn58PT0hExW96oasxu5kclkaN68eaO+h0ql4v8xDQh/H4aFvw/Dwt+H4eHv5O7uNWJThQuKiYiIyKSw3BAREZFJYbnRI4VCgQULFkChUEgdhcDfh6Hh78Ow8PdhePg70R+zW1BMREREpo0jN0RERGRSWG6IiIjIpLDcEBERkUlhuSEiIiKTwnKjJ6tXr4avry+sra0RHByMEydOSB3JbC1ZsgQ9e/aEUqmEm5sbHnvsMcTGxkodi2577733IAgCZs2aJXUUs3Xz5k0888wzcHZ2ho2NDTp37oxTp05JHcssaTQazJs3D35+frCxsUGrVq3wzjvv1Ov+SXR3LDd6sGnTJoSHh2PBggU4c+YMAgICMGzYMKSlpUkdzSz98ccfmDp1Ko4dO4Z9+/ahvLwcQ4cORWFhodTRzN7Jkyfx6aefokuXLlJHMVvZ2dkICQmBpaUldu3ahYsXL2LZsmVwdHSUOppZev/997F27VqsWrUKMTExeP/99/HBBx9g5cqVUkczajwVXA+Cg4PRs2dPrFq1CkDl/au8vb0xffp0zJkzR+J0lJ6eDjc3N/zxxx/o37+/1HHMVkFBAbp164Y1a9bg3XffRdeuXbF8+XKpY5mdOXPm4MiRIzh06JDUUQjAI488ArVajc8//1y3bfTo0bCxscG3334rYTLjxpGbB1RWVobTp08jNDRUt00mkyE0NBRHjx6VMBlVyc3NBQA4OTlJnMS8TZ06FSNGjKj2zwo1vZ9//hk9evTAmDFj4ObmhsDAQGzYsEHqWGarT58+iIiIQFxcHADg3LlzOHz4MMLCwiROZtzM7saZ+paRkQGNRgO1Wl1tu1qtxqVLlyRKRVW0Wi1mzZqFkJAQdOrUSeo4ZuuHH37AmTNncPLkSamjmL34+HisXbsW4eHh+O9//4uTJ09ixowZsLKywqRJk6SOZ3bmzJmDvLw8tG/fHnK5HBqNBosWLcKECROkjmbUWG7IpE2dOhXR0dE4fPiw1FHMVlJSEmbOnIl9+/bB2tpa6jhmT6vVokePHli8eDEAIDAwENHR0Vi3bh3LjQQ2b96M7777Dhs3boS/vz+ioqIwa9YseHp68vfxAFhuHpCLiwvkcjlSU1OrbU9NTYW7u7tEqQgApk2bhl9//RWRkZFo3ry51HHM1unTp5GWloZu3brptmk0GkRGRmLVqlUoLS2FXC6XMKF58fDwQMeOHatt69ChA7Zt2yZRIvP2+uuvY86cOXjqqacAAJ07d0ZCQgKWLFnCcvMAuObmAVlZWaF79+6IiIjQbdNqtYiIiEDv3r0lTGa+RFHEtGnTsH37dvz+++/w8/OTOpJZGzx4MM6fP4+oqCjdo0ePHpgwYQKioqJYbJpYSEhIjUsjxMXFoUWLFhIlMm9FRUWQyap/Fcvlcmi1WokSmQaO3OhBeHg4Jk2ahB49eiAoKAjLly9HYWEhJk+eLHU0szR16lRs3LgRP/30E5RKJVJSUgAADg4OsLGxkTid+VEqlTXWO9nZ2cHZ2ZnroCQwe/Zs9OnTB4sXL8bYsWNx4sQJrF+/HuvXr5c6mlkaOXIkFi1aBB8fH/j7++Ps2bP46KOP8Pzzz0sdzajxVHA9WbVqFZYuXYqUlBR07doVK1asQHBwsNSxzJIgCLVu/+KLL/Dcc881bRiq1cCBA3kquIR+/fVXzJ07F5cvX4afnx/Cw8Px73//W+pYZik/Px/z5s3D9u3bkZaWBk9PTzz99NOYP38+rKyspI5ntFhuiIiIyKRwzQ0RERGZFJYbIiIiMiksN0RERGRSWG6IiIjIpLDcEBERkUlhuSEiIiKTwnJDREREJoXlhojMniAI2LFjh9QxiEhPWG6ISFLPPfccBEGo8Xj44YeljkZERor3liIiyT388MP44osvqm1TKBQSpSEiY8eRGyKSnEKhgLu7e7WHo6MjgMopo7Vr1yIsLAw2NjZo2bIltm7dWu348+fP46GHHoKNjQ2cnZ3x4osvoqCgoNo+//d//wd/f38oFAp4eHhg2rRp1Z7PyMjA448/DltbW7Rp0wY///xz435oImo0LDdEZPDmzZuH0aNH49y5c5gwYQKeeuopxMTEAAAKCwsxbNgwODo64uTJk9iyZQv2799frbysXbsWU6dOxYsvvojz58/j559/RuvWrau9x8KFCzF27Fj89ddfGD58OCZMmICsrKwm/ZxEpCciEZGEJk2aJMrlctHOzq7aY9GiRaIoiiIAccqUKdWOCQ4OFl9++WVRFEVx/fr1oqOjo1hQUKB7/rfffhNlMpmYkpIiiqIoenp6iv/73//umgGA+Oabb+p+LigoEAGIu3bt0tvnJKKmwzU3RCS5QYMGYe3atdW2OTk56f7cu3fvas/17t0bUVFRAICYmBgEBATAzs5O93xISAi0Wi1iY2MhCAJu3bqFwYMH15mhS5cuuj/b2dlBpVIhLS3tfj8SEUmI5YaIJGdnZ1djmkhfbGxs6rWfpaVltZ8FQYBWq22MSETUyLjmhogM3rFjx2r83KFDBwBAhw4dcO7cORQWFuqeP3LkCGQyGdq1awelUglfX19EREQ0aWYikg5HbohIcqWlpUhJSam2zcLCAi4uLgCALVu2oEePHujbty++++47nDhxAp9//jkAYMKECViwYAEmTZqEt956C+np6Zg+fTqeffZZqNVqAMBbb72FKVOmwM3NDWFhYcjPz8eRI0cwffr0pv2gRNQkWG6ISHK7d++Gh4dHtW3t2rXDpUuXAFSeyfTDDz/glVdegYeHB77//nt07NgRAGBra4s9e/Zg5syZ6NmzJ2xtbTF69Gh89NFHuteaNGkSSkpK8PHHH+O1116Di4sLnnzyyab7gETUpARRFEWpQxAR3Y0gCNi+fTsee+wxqaMQkZHgmhsiIiIyKSw3REREZFK45oaIDBpnzomooThyQ0RERCaF5YaIiIhMCssNERERmRSWGyIiIjIpLDdERERkUlhuiIiIyKSw3BAREZFJYbkhIiIik8JyQ0RERCbl/wF2jn3pwjI72AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Tone - Accuracy: 0.9515, Precision: 0.9513, Recall: 0.9515, F1: 0.9513\n",
      "Tone Confusion Matrix:\n",
      " [[304  28]\n",
      " [ 20 637]]\n",
      "Tone Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       332\n",
      "           1       0.96      0.97      0.96       657\n",
      "\n",
      "    accuracy                           0.95       989\n",
      "   macro avg       0.95      0.94      0.95       989\n",
      "weighted avg       0.95      0.95      0.95       989\n",
      "\n",
      "Intent - Accuracy: 0.9323, Precision: 0.9317, Recall: 0.9323, F1: 0.9318\n",
      "Intent Confusion Matrix:\n",
      " [[ 59  11   6   4]\n",
      " [  9 538   3  14]\n",
      " [  1   4 122   3]\n",
      " [  4   8   0 203]]\n",
      "Intent Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77        80\n",
      "           1       0.96      0.95      0.96       564\n",
      "           2       0.93      0.94      0.93       130\n",
      "           3       0.91      0.94      0.92       215\n",
      "\n",
      "    accuracy                           0.93       989\n",
      "   macro avg       0.90      0.89      0.90       989\n",
      "weighted avg       0.93      0.93      0.93       989\n",
      "\n",
      "총 학습 시간 : 864.2802970409393\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화 알고리즘 정의\n",
    "model = My_Transformer(d_model, num_heads, num_layers, d_ff, vocab_size, num_tone_labels, num_intent_labels)\n",
    "count_parameters(model)\n",
    "\n",
    "tone_criterion = nn.CrossEntropyLoss()\n",
    "intent_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.2) # 1 에폭마다 학습률을 0.1배로 감소\n",
    "\n",
    "\n",
    "# 학습 루프\n",
    "begin_time = time.time()\n",
    "print('학습 시작')\n",
    "train_losses = [] # loss를 저장할 리스트\n",
    "\n",
    "for epoch in range(tot_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # 훈련 루프\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        src_data, tone_labels, intent_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        tone_pred, intent_pred, _ = model(src_data)\n",
    "        tone_loss = tone_criterion(tone_pred, tone_labels)\n",
    "        intent_loss = intent_criterion(intent_pred, intent_labels)\n",
    "        loss = tone_loss + intent_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 훈련 데이터에 대한 예측\n",
    "    train_tone_preds = []\n",
    "    train_intent_preds = []\n",
    "    train_tone_labels = []\n",
    "    train_intent_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_dataloader:\n",
    "            src_data, tone_labels, intent_labels = batch\n",
    "            tone_pred, intent_pred, _ = model(src_data)\n",
    "            train_tone_preds.extend(torch.argmax(tone_pred, dim=1).tolist())\n",
    "            train_intent_preds.extend(torch.argmax(intent_pred, dim=1).tolist())\n",
    "            train_tone_labels.extend(tone_labels.tolist())\n",
    "            train_intent_labels.extend(intent_labels.tolist())\n",
    "\n",
    "    # 훈련 데이터에 대한 혼동 행렬 및 분류 보고서 (tone)\n",
    "    train_tone_cm = confusion_matrix(train_tone_labels, train_tone_preds)\n",
    "    train_tone_cr = classification_report(train_tone_labels, train_tone_preds)\n",
    "    print(\"Train Tone Confusion Matrix:\\n\", train_tone_cm)\n",
    "    print(\"Train Tone Classification Report:\\n\", train_tone_cr)\n",
    "\n",
    "    # 훈련 데이터에 대한 혼동 행렬 및 분류 보고서 (intent)\n",
    "    train_intent_cm = confusion_matrix(train_intent_labels, train_intent_preds)\n",
    "    train_intent_cr = classification_report(train_intent_labels, train_intent_preds)\n",
    "    print(\"Train Intent Confusion Matrix:\\n\", train_intent_cm)\n",
    "    print(\"Train Intent Classification Report:\\n\", train_intent_cr)\n",
    "        \n",
    "    train_losses.append(train_loss/len(train_dataloader)) # 에폭별 평균 loss 저장\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{tot_epoch}, Train Loss: {train_loss/len(train_dataloader):.4f}\")\n",
    "    print(f\"Time: {epoch_end_time-epoch_start_time:.2f}s\") # 각 에폭의 시간만 출력\n",
    "    print()\n",
    "    # scheduler.step()\n",
    "\n",
    "print('학습종료')\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Train Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장 (학습 후)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab': vocab,\n",
    "    'd_model': d_model,\n",
    "    'num_heads': num_heads,\n",
    "    'num_layers': num_layers,\n",
    "    'd_ff': d_ff,\n",
    "    'dropout': dropout,\n",
    "    'num_tone_labels': num_tone_labels,\n",
    "    'num_intent_labels' : num_intent_labels\n",
    "}, \"model/llm_transformer.pt\") # 모델 전체 저장\n",
    "\n",
    "\n",
    "# 모든 훈련이 끝난 후 테스트 진행\n",
    "test_tone_loss, all_tone_preds, all_tone_labels, test_intent_loss, all_intent_preds, all_intent_labels = evaluate(model, test_dataloader, tone_criterion, intent_criterion)\n",
    "\n",
    "# test_tone_loss, all_tone_preds, all_tone_labels = evaluate(model, test_dataloader, tone_criterion)\n",
    "# test_intent_loss, all_intent_preds, all_intent_labels = evaluate(model, test_dataloader, intent_criterion)\n",
    "\n",
    "tone_accuracy = accuracy_score(all_tone_labels, all_tone_preds)\n",
    "tone_precision, tone_recall, tone_f1, _ = precision_recall_fscore_support(all_tone_labels, all_tone_preds, average='weighted')\n",
    "tone_cm = confusion_matrix(all_tone_labels, all_tone_preds)\n",
    "tone_cr = classification_report(all_tone_labels, all_tone_preds)\n",
    "\n",
    "intent_accuracy = accuracy_score(all_intent_labels, all_intent_preds)\n",
    "intent_precision, intent_recall, intent_f1, _ = precision_recall_fscore_support(all_intent_labels, all_intent_preds, average='weighted')\n",
    "intent_cm = confusion_matrix(all_intent_labels, all_intent_preds)\n",
    "intent_cr = classification_report(all_intent_labels, all_intent_preds)\n",
    "\n",
    "print(\"Test Results:\") # 테스트 결과임을 명시\n",
    "print(f\"Tone - Accuracy: {tone_accuracy:.4f}, Precision: {tone_precision:.4f}, Recall: {tone_recall:.4f}, F1: {tone_f1:.4f}\")\n",
    "print(\"Tone Confusion Matrix:\\n\", tone_cm)\n",
    "print(\"Tone Classification Report:\\n\", tone_cr)\n",
    "\n",
    "print(f\"Intent - Accuracy: {intent_accuracy:.4f}, Precision: {intent_precision:.4f}, Recall: {intent_recall:.4f}, F1: {intent_f1:.4f}\")\n",
    "print(\"Intent Confusion Matrix:\\n\", intent_cm)\n",
    "print(\"Intent Classification Report:\\n\", intent_cr)\n",
    "\n",
    "print(f'총 학습 시간 : {time.time() - begin_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장 및 어휘 사전(vocab) 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 가중치 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 (학습 후)\n",
    "torch.save(model.state_dict(), \"model/llm_transformer_weights.pt\")\n",
    "print(\"모델 가중치 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 핵심 단어 추출 (학습 및 테스트 이후) ***\n",
    "sample_text = test_df['original_text'].iloc[0] # 테스트 데이터 중 하나 선택\n",
    "print(\"Original Text:\", sample_text)\n",
    "\n",
    "# 빈 텍스트 또는 토큰화 후 길이가 0인 경우 처리\n",
    "if not sample_text or not sample_text.split():\n",
    "    keywords = []  # 빈 리스트 반환\n",
    "else:\n",
    "    keywords = extract_keywords(model, sample_text, vocab, top_k=20, device=\"cpu\") # device 설정 중요\n",
    "print(\"Extracted Keywords:\", keywords)\n",
    "\n",
    "# 전체 테스트 데이터에 대해 핵심 단어 추출 (선택적, 안정성 향상)\n",
    "def extract_keywords_safe(text):\n",
    "    if not text or not text.split():\n",
    "        return []\n",
    "    else:\n",
    "        return extract_keywords(model, text, vocab, top_k=5, device=\"cpu\")\n",
    "\n",
    "test_df['keywords'] = test_df['original_text'].apply(extract_keywords_safe)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 읽어오기\n",
    "try:\n",
    "    df = pd.read_csv(\"data/question.csv\", encoding='utf-8') # UTF-8 인코딩으로 읽기, 필요에 따라 encoding='cp949' 등으로 변경\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: data/question.csv 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n",
    "    exit()\n",
    "\n",
    "# \"?\" 제거하고 cleaned_question 열 생성\n",
    "df['cleaned_question_text'] = df['question_text'].str.replace('?', '', regex=False) # regex=False로 정규표현식 사용 안 함\n",
    "\n",
    "# 정규표현식으로 \"?\" 포함 다른 특수문자 제거 (필요한 경우)\n",
    "# 특수문자 제거를 원할 경우 아래 주석을 해제하고 사용하세요.\n",
    "# df['cleaned_question'] = df['question_text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# 변경된 DataFrame을 새로운 CSV 파일로 저장\n",
    "try:\n",
    "    df.to_csv(\"data/cleaned_question.csv\", index=False, encoding='utf-8') # UTF-8 인코딩으로 저장\n",
    "    print(\"cleaned_question.csv 파일이 성공적으로 생성되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: 파일 저장 중 오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 결과 확인 (선택적)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "d_model : 512, num_heads : 8\n",
      "각 머리당 처리될 차원 수 : 64\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Extracted Keywords: [1581, 151, 4788, 1167, 46, 2220, 86, 4789, 23, 421]\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13]), torch.Size([1, 8, 13, 13])]\n",
      "Shape of avg_attn_weights: torch.Size([13, 13])\n",
      "Shape of word_importances: torch.Size([13])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11])]\n",
      "Shape of avg_attn_weights: torch.Size([11, 11])\n",
      "Shape of word_importances: torch.Size([11])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12]), torch.Size([1, 8, 12, 12])]\n",
      "Shape of avg_attn_weights: torch.Size([12, 12])\n",
      "Shape of word_importances: torch.Size([12])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11])]\n",
      "Shape of avg_attn_weights: torch.Size([11, 11])\n",
      "Shape of word_importances: torch.Size([11])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11]), torch.Size([1, 8, 11, 11])]\n",
      "Shape of avg_attn_weights: torch.Size([11, 11])\n",
      "Shape of word_importances: torch.Size([11])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "                    original_text                keywords\n",
      "0  기억을 다 잃게 되었을 때 단 한명만 기억할 수 있다면     [수, 기억을, 단, 있다면, 다]\n",
      "1                신발끈 묶어줄 것 같은 사람은  [같은, 신발끈, 묶어줄, 것, 사람은]\n",
      "2         이번 겨울에 스키장 같이 가고 싶은 사람은  [같이, 겨울에, 싶은, 이번, 스키장]\n",
      "3       친구 중에 가장 좋은 학교에 갈거 같은 사람은   [좋은, 같은, 갈거, 학교에, 친구]\n",
      "4            달을 보고 가장 먼저 생각나는 사람은  [생각나는, 가장, 달을, 보고, 먼저]\n",
      "Word2Vec 모델 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드 (수정됨)\n",
    "checkpoint = torch.load(\"model/llm_transformer.pt\")\n",
    "vocab = checkpoint['vocab']\n",
    "vocab_size = len(vocab)\n",
    "d_model = checkpoint['d_model']\n",
    "num_heads = checkpoint['num_heads']\n",
    "num_layers = checkpoint['num_layers']\n",
    "d_ff = checkpoint['d_ff']\n",
    "dropout = checkpoint['dropout'] # dropout 값은 로드하지만, 모델 생성 시에는 사용하지 않음\n",
    "num_tone_labels = checkpoint['num_tone_labels']\n",
    "num_intent_labels = checkpoint['num_intent_labels']\n",
    "\n",
    "model = My_Transformer(d_model, num_heads, num_layers, d_ff, vocab_size, num_tone_labels, num_intent_labels) # dropout 없이 모델 생성\n",
    "model.load_state_dict(checkpoint['model_state_dict']) # 가중치 로드\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# 키워드 추출\n",
    "sample_text = test_texts[0]\n",
    "keywords = extract_keywords(model, sample_text, vocab, top_k=20, device=\"cpu\")\n",
    "print(\"Extracted Keywords:\", keywords)\n",
    "\n",
    "# 전체 테스트 데이터에 대해 핵심 단어 추출\n",
    "test_df = pd.DataFrame({'original_text': [restore_text(text, index_to_word) for text in test_texts]})\n",
    "test_df['keywords'] = test_df['original_text'].apply(extract_keywords_safe)\n",
    "print(test_df.head())\n",
    "\n",
    "# --- Word2Vec 모델 학습 및 저장 (별도 실행 또는 필요할 때만 실행) ---\n",
    "def train_word2vec(df, save_path=\"model/word2vec.model\"):\n",
    "    okt = Okt()\n",
    "    corpus = [okt.nouns(text) for text in df['cleaned_question_text']]\n",
    "    w2v_model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    w2v_model.save(save_path)\n",
    "    print(\"Word2Vec 모델 저장 완료\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"data/cleaned_question.csv\")\n",
    "    # df = pd.read_csv(\"data/question_categorize.csv\")\n",
    "    train_word2vec(df)\n",
    "except FileNotFoundError:\n",
    "    print(\"CSV 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "# Word2Vec 모델 로드 (키워드 추출 시)\n",
    "w2v_model = Word2Vec.load(\"model/word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1]), torch.Size([1, 8, 1, 1])]\n",
      "Shape of avg_attn_weights: torch.Size([1, 1])\n",
      "Shape of word_importances: torch.Size([1])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3]), torch.Size([1, 8, 3, 3])]\n",
      "Shape of avg_attn_weights: torch.Size([3, 3])\n",
      "Shape of word_importances: torch.Size([3])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10]), torch.Size([1, 8, 10, 10])]\n",
      "Shape of avg_attn_weights: torch.Size([10, 10])\n",
      "Shape of word_importances: torch.Size([10])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9]), torch.Size([1, 8, 9, 9])]\n",
      "Shape of avg_attn_weights: torch.Size([9, 9])\n",
      "Shape of word_importances: torch.Size([9])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8]), torch.Size([1, 8, 8, 8])]\n",
      "Shape of avg_attn_weights: torch.Size([8, 8])\n",
      "Shape of word_importances: torch.Size([8])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2]), torch.Size([1, 8, 2, 2])]\n",
      "Shape of avg_attn_weights: torch.Size([2, 2])\n",
      "Shape of word_importances: torch.Size([2])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7]), torch.Size([1, 8, 7, 7])]\n",
      "Shape of avg_attn_weights: torch.Size([7, 7])\n",
      "Shape of word_importances: torch.Size([7])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6]), torch.Size([1, 8, 6, 6])]\n",
      "Shape of avg_attn_weights: torch.Size([6, 6])\n",
      "Shape of word_importances: torch.Size([6])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5]), torch.Size([1, 8, 5, 5])]\n",
      "Shape of avg_attn_weights: torch.Size([5, 5])\n",
      "Shape of word_importances: torch.Size([5])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "Shape of all_encoder_attn_weights: [torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 4])]\n",
      "Shape of avg_attn_weights: torch.Size([4, 4])\n",
      "Shape of word_importances: torch.Size([4])\n",
      "키워드 추출 완료 및 결과 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# combined_keyword_extraction 함수 사용 예시\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['cleaned_question_text']\n",
    "    keywords_with_w2v = combined_keyword_extraction(model, text, vocab, top_k=5, device=\"cpu\", w2v_model=w2v_model)\n",
    "    keywords_without_w2v = combined_keyword_extraction(model, text, vocab, top_k=5, device=\"cpu\")\n",
    "\n",
    "    results.append({\n",
    "        'index': index,\n",
    "        'text': text,\n",
    "        'keywords_with_w2v': keywords_with_w2v,\n",
    "        'keywords_without_w2v': keywords_without_w2v\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"best_keyword_extraction_results.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "print(\"키워드 추출 완료 및 결과 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
