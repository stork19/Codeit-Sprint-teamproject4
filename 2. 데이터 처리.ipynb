{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팀프로젝트4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from google.cloud import storage, bigquery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 파일 용량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 용량 확인\n",
    "def get_csv_file_sizes(directory):\n",
    "    file_sizes = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.parquet'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "            file_sizes[filename] = file_size_mb\n",
    "    return file_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '데이터가 저장된 위치'\n",
    "directory = './origin_data'\n",
    "csv_file_sizes = get_csv_file_sizes(directory)\n",
    "sorted_dict = dict(sorted(csv_file_sizes.items(), key=lambda item: item[1], reverse=True))\n",
    "for filename, size in sorted_dict.items():\n",
    "    print(f'{filename:<50}: {size:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCS로 부터 parquet파일 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수에 JSON 키 파일 설정\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./config/codeit-project-567b5092fd38.json\"\n",
    "\n",
    "# GCS 클라이언트 및 BigQuery 클라이언트 초기화\n",
    "storage_client = storage.Client()\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "def download_parquet_from_gcs(bucket_name, prefix):\n",
    "    \"\"\"\n",
    "    GCS에서 Parquet 파일 다운로드 및 병합.\n",
    "    :param bucket_name: GCS 버킷 이름\n",
    "    :param prefix: 다운로드할 경로 (GCS 버킷 내부 폴더)\n",
    "    :return: 파일별 데이터프레임 딕셔너리 (key: 파일 이름, value: 데이터프레임)\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)  # 지정된 경로의 파일 검색\n",
    "    dataframes = {}  # 파일별 데이터프레임 저장\n",
    "    file_names = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".parquet\"):\n",
    "            file_name = blob.name.split(\"/\")[-1].replace(\".parquet\", \"\")  # 파일 이름 추출\n",
    "            print(f\"Downloading: {blob.name}\")\n",
    "            # GCS에서 바로 메모리로 읽기\n",
    "            with blob.open(\"rb\") as file:\n",
    "                df = pd.read_parquet(file, engine=\"pyarrow\")\n",
    "                dataframes[file_name] = df\n",
    "                file_names.append(file_name)\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"No Parquet files found at prefix: {prefix}\")\n",
    "    return dataframes, file_names  # 파일 이름별 데이터프레임 딕셔너리 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그냥 데이터 다운로드만 하고 확인 할 때 사용.\n",
    "## 실행, prefix, dataset_name은 동일하게 들어갈 것 같습니다.\n",
    "if __name__ == \"__main__\":\n",
    "    db_name = \"origin/hackle\"\n",
    "    bucket_name = \"finalproject_sprint\"\n",
    "    prefix = db_name  # GCS 내부의 특정 경로(버킷에서 파일이 저장된 폴더 이름.)\n",
    "    # dataset_name = db_name  # 데이터셋 이름 지정\n",
    "\n",
    "    # GCS에서 Parquet 데이터 다운로드\n",
    "    dataframes, file_names = download_parquet_from_gcs(bucket_name, prefix)\n",
    "    print()\n",
    "    print(f\"DB name : {db_name}, \\ntable_name : {file_names}\")\n",
    "\n",
    "    # GCS에서 받은 parquet의 file이름으로 데이터 저장\n",
    "    for file_name in file_names:\n",
    "        globals()[file_name] = dataframes[f'{file_name}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 경로 설정\n",
    "output_dir = \"./modified_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # 저장 디렉토리 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(device_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_properties['device_vendor'].unique(), device_properties['device_vendor'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_properties['device_vendor'] = device_properties['device_vendor'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_properties['device_vendor'].unique(), device_properties['device_vendor'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_properties.to_parquet('modified_data/hackle_device_properties.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_properties[user_properties['user_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자가 아닌 값들만 필터링하는 코드\n",
    "non_numeric_ids = user_properties[user_properties['user_id'].apply(lambda x: not str(x).isdigit())]\n",
    "\n",
    "# 결과 확인\n",
    "print(non_numeric_ids)\n",
    "\n",
    "## 해당부분을 확인한 결과 df내부에 존재한것으로 확인됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(user_properties['gender'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_properties['grade'] = user_properties['grade'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(user_properties['grade'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_properties.to_parquet('data1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hackle_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_properties['session_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts()를 사용하여 각 값의 개수 계산\n",
    "value_counts = hackle_properties['session_id'].value_counts()\n",
    "\n",
    "# 값이 2 이상인 것만 필터링\n",
    "filtered_counts = value_counts[value_counts >= 2]\n",
    "\n",
    "# 결과 확인\n",
    "print(filtered_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링된 결과를 데이터프레임으로 변환\n",
    "## 이부분은 versionname이 가장 높은 버전을 기준으로 데이터를 slicing\n",
    "## 기존의 versionname이 낮은 데이터를 삭제.\n",
    "filtered_df = hackle_properties[hackle_properties['session_id'].isin(filtered_counts.index)]\n",
    "filtered_df['versionname'] = filtered_df['versionname'].apply(LooseVersion)\n",
    "\n",
    "filtered_df2 = hackle_properties[~hackle_properties['session_id'].isin(filtered_counts.index)]\n",
    "\n",
    "latest_version = filtered_df.loc[filtered_df.groupby('session_id')['versionname'].idxmax()] ## 디테일하게 할 꺼면 수정! \n",
    "latest_version['versionname'] = latest_version['versionname'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_user_id = filtered_df2[filtered_df2['user_id'].isin([''])]['session_id'].tolist()\n",
    "\n",
    "user_properties[user_properties['user_id'].isin(none_user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2[filtered_df2['user_id'].isin(['', ' ', 'null', 'None', None, pd.NA])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_version.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([latest_version, filtered_df2], axis=0)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "# filtered_hackle_properties\n",
    "missing_values = latest_version[latest_version.isnull().any(axis=1)]\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_parquet('modified_data/hackle_hackle_properties.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hackle_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(hackle_events.head())\n",
    "hackle_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events[hackle_events['event_datetime'].isin(['', ' ', 'null', 'None', None, pd.NA])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events[hackle_events['session_id'].isin(['', ' ', 'null', 'None', None, pd.NA])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events[hackle_events['session_id'].str.strip().isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.to_parquet(\"modified_data/hackle_hackle_events.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### master table\n",
    "\n",
    "- hackle_events table을 기준으로 참고가능한 columns을 붙여서 master table 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = hackle_events.merge(total_df, how='left', on='session_id')\n",
    "merge_df.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.merge(device_properties, how='left', on='device_id')\n",
    "merge_df.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hackle_events datetime 정렬\n",
    "hackle_events = hackle_events.sort_values(by='event_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events['event_key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events[hackle_events['event_key'] == 'click_question_ask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events[\"event_date\"] = hackle_events[\"event_datetime\"].dt.date\n",
    "\n",
    "# DAU 계산\n",
    "dau = hackle_events.groupby(\"event_date\")[\"session_id\"].nunique()\n",
    "print(\"DAU:\\n\", dau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "dau.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Daily Active Users (DAU)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Unique Users\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events['week'] = hackle_events['event_datetime'].dt.strftime(\"%Y-%U\")\n",
    "wau = hackle_events.groupby(\"week\")['session_id'].nunique()\n",
    "print(\"WAU: \\n\", wau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "wau.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Weekly Active Users (WAU)\", fontsize=16)\n",
    "plt.xlabel(\"Week\", fontsize=12)\n",
    "plt.ylabel(\"Unique Users\", fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohort(weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events['event_date'] = pd.to_datetime(hackle_events['event_date'], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohort(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 코호트 계산을 위해서 처음 접속 날짜 계산\n",
    "hackle_events['first_date'] = hackle_events.groupby('session_id')['event_datetime'].transform(\"min\").dt.date\n",
    "hackle_events['first_date'] = pd.to_datetime(hackle_events['first_date'])\n",
    "\n",
    "## 접속한 주차 계산(1주, 2주, 3주..)\n",
    "hackle_events['cohort_day'] = (hackle_events['event_date'] - hackle_events['first_date']).dt.days\n",
    "\n",
    "## Cohort Retention table create\n",
    "cohort = hackle_events.groupby(['first_date', 'cohort_day'])['session_id'].nunique().unstack(1)\n",
    "\n",
    "## chort retension ratio\n",
    "cohort_retention_daily = cohort.divide(cohort.iloc[:, 0], axis=0) * 100\n",
    "\n",
    "cohort_retention_daily.index = cohort_retention_daily.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(cohort_retention_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(cohort_retention_daily, annot=True, fmt='.1f', cmap='Reds', cbar_kws={\"label\": \"Retention Rate (%)\"})\n",
    "plt.title(\"Cohort Retention Analysis(Daily)\", fontsize=16)\n",
    "plt.xlabel(\"Cohort Day\", fontsize=12)\n",
    "plt.ylabel(\"First Active Date\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohort(Weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 코호트 계산을 위해서 처음 접속 날짜 계산\n",
    "hackle_events['first_date'] = hackle_events.groupby('session_id')['event_datetime'].transform(\"min\").dt.date\n",
    "\n",
    "# 첫 접속이 속한 주의 첫 날짜를 기준으로 주차를 계산\n",
    "hackle_events[\"first_week_start\"] = pd.to_datetime(hackle_events[\"first_date\"]).dt.to_period(\"W\").dt.start_time\n",
    "\n",
    "## 접속한 주차 계산(1주, 2주, 3주..)\n",
    "hackle_events[\"cohort_week\"] = (hackle_events[\"event_date\"].dt.to_period(\"W\").dt.start_time - hackle_events[\"first_week_start\"]).dt.days // 7\n",
    "\n",
    "## Cohort Retention table create\n",
    "cohort = hackle_events.groupby(['first_week_start', 'cohort_week'])['session_id'].nunique().unstack(1)\n",
    "\n",
    "## chort retension ratio\n",
    "cohort_retention_weekly = cohort.divide(cohort.iloc[:, 0], axis=0) * 100\n",
    "\n",
    "cohort_retention_weekly.index = cohort_retention_weekly.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(\"주 단위 Cohort Retention:\")\n",
    "print(cohort_retention_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(cohort_retention_weekly, annot=True, fmt='.1f', cmap='Reds', cbar_kws={\"label\": \"Retention Rate (%)\"})\n",
    "plt.title(\"Cohort Retention Analysis(Weekly)\", fontsize=16)\n",
    "plt.xlabel(\"Cohort Week\", fontsize=12)\n",
    "plt.ylabel(\"First Active Date\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일별 평균 이벤트 수 계산\n",
    "engagement = hackle_events.groupby(\"event_date\")[\"event_key\"].count() / hackle_events.groupby(\"event_date\")[\"event_key\"].nunique()\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "engagement.plot(kind=\"line\", marker=\"o\", color=\"green\")\n",
    "plt.title(\"User Engagement (Average Events per User)\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Average Events per User\", fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aoripi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackle_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import random\n",
    "\n",
    "\n",
    "df = hackle_events[['session_id', 'event_datetime', 'event_key']]\n",
    "\n",
    "session_ids = df['session_id'].unique()\n",
    "sample_size = int(len(session_ids) * 0.1) # 샘플 비율 조정\n",
    "sampled_session_ids = random.sample(session_ids.tolist(), sample_size)\n",
    "df_sampled = df[df['session_id'].isin(sampled_session_ids)]\n",
    "\n",
    "print(\"샘플링된 데이터 크기:\", len(df_sampled))\n",
    "\n",
    "user_events_sampled = df_sampled.groupby('session_id')['event_key'].apply(list).tolist()\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary_sampled = te.fit(user_events_sampled).transform(user_events_sampled)\n",
    "df_encoded_sampled = pd.DataFrame(te_ary_sampled, columns=te.columns_)\n",
    "\n",
    "frequent_itemsets_sampled = apriori(df_encoded_sampled, min_support=0.1, use_colnames=True) # min_support 조정\n",
    "\n",
    "print(frequent_itemsets_sampled)\n",
    "if frequent_itemsets_sampled.empty:\n",
    "    print(\"frequent_itemsets_sampled가 비어 있습니다. 데이터 또는 min_support 값을 확인하세요.\")\n",
    "    print(\"df_encoded_sampled shape:\", df_encoded_sampled.shape)\n",
    "    print(df_encoded_sampled.head())\n",
    "    exit()\n",
    "\n",
    "rules_sampled = association_rules(frequent_itemsets_sampled, metric=\"confidence\", min_threshold=0.5)\n",
    "rules_lift_sampled = association_rules(frequent_itemsets_sampled, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "print(\"\\n샘플 데이터의 빈발 항목 집합:\\n\",frequent_itemsets_sampled)\n",
    "print(\"\\n샘플 데이터의 연관 규칙:\\n\", rules_sampled)\n",
    "print(\"\\n샘플 데이터의 향상도 기반 규칙:\\n\",rules_lift_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### event_key pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = hackle_events['event_key'].value_counts()\n",
    "ratios = (counts / hackle_events.shape[0]) * 100\n",
    "\n",
    "# 비율이 3% 미만인 이벤트들을 \"others\"로 합산\n",
    "others_ratio = ratios[ratios < 3].sum()\n",
    "\n",
    "# \"others\" 항목 생성\n",
    "ratios = ratios[ratios >= 3]  # 3% 이상인 비율만 남기고\n",
    "ratios[\"other_events\"] = others_ratio  # \"others\" 항목 추가\n",
    "\n",
    "# 결과 출력\n",
    "print(ratios)\n",
    "ratios_df = pd.DataFrame(ratios).reset_index(level=0)\n",
    "ratios_df.to_csv('ratios.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원형 차트 그리기\n",
    "plt.figure(figsize=(9, 9))  # 차트 크기 설정\n",
    "plt.pie(\n",
    "    ratios, \n",
    "    labels=ratios.index,  # 라벨 설정\n",
    "    autopct='%1.1f%%',    # 퍼센트 표시\n",
    "    startangle=90,        # 시작 각도\n",
    "    colors=plt.cm.tab10.colors  # 색상 팔레트 선택 (옵션)\n",
    ")\n",
    "\n",
    "plt.title('Ratio(%) of Each Events')  # 제목 설정\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
