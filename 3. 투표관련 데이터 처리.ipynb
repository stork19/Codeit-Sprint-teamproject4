{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 팀프로젝트4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from google.cloud import storage, bigquery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 파일 용량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 용량 확인\n",
    "def get_csv_file_sizes(directory):\n",
    "    file_sizes = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.parquet'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "            file_sizes[filename] = file_size_mb\n",
    "    return file_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '데이터가 저장된 위치'\n",
    "directory = './origin_data'\n",
    "csv_file_sizes = get_csv_file_sizes(directory)\n",
    "sorted_dict = dict(sorted(csv_file_sizes.items(), key=lambda item: item[1], reverse=True))\n",
    "for filename, size in sorted_dict.items():\n",
    "    print(f'{filename:<50}: {size:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCS로 부터 parquet파일 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수에 JSON 키 파일 설정\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./config/codeit-project-567b5092fd38.json\"\n",
    "\n",
    "# GCS 클라이언트 및 BigQuery 클라이언트 초기화\n",
    "storage_client = storage.Client()\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "def download_parquet_from_gcs(bucket_name, prefix):\n",
    "    \"\"\"\n",
    "    GCS에서 Parquet 파일 다운로드 및 병합.\n",
    "    :param bucket_name: GCS 버킷 이름\n",
    "    :param prefix: 다운로드할 경로 (GCS 버킷 내부 폴더)\n",
    "    :return: 파일별 데이터프레임 딕셔너리 (key: 파일 이름, value: 데이터프레임)\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)  # 지정된 경로의 파일 검색\n",
    "    dataframes = {}  # 파일별 데이터프레임 저장\n",
    "    file_names = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".parquet\"):\n",
    "            file_name = blob.name.split(\"/\")[-1].replace(\".parquet\", \"\")  # 파일 이름 추출\n",
    "            print(f\"Downloading: {blob.name}\")\n",
    "            # GCS에서 바로 메모리로 읽기\n",
    "            with blob.open(\"rb\") as file:\n",
    "                df = pd.read_parquet(file, engine=\"pyarrow\")\n",
    "                dataframes[file_name] = df\n",
    "                file_names.append(file_name)\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"No Parquet files found at prefix: {prefix}\")\n",
    "    return dataframes, file_names  # 파일 이름별 데이터프레임 딕셔너리 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그냥 데이터 다운로드만 하고 확인 할 때 사용.\n",
    "## 실행, prefix, dataset_name은 동일하게 들어갈 것 같습니다.\n",
    "if __name__ == \"__main__\":\n",
    "    db_name = \"origin/votes\"\n",
    "    bucket_name = \"finalproject_sprint\"\n",
    "    prefix = db_name  # GCS 내부의 특정 경로(버킷에서 파일이 저장된 폴더 이름.)\n",
    "    dataset_name = db_name  # 데이터셋 이름 지정\n",
    "\n",
    "    # GCS에서 Parquet 데이터 다운로드\n",
    "    dataframes, file_names = download_parquet_from_gcs(bucket_name, prefix)\n",
    "    print(f\"DB name : {db_name}, table_name : {file_names}\")\n",
    "\n",
    "    # GCS에서 받은 parquet의 file이름으로 데이터 저장\n",
    "    for file_name in file_names:\n",
    "        globals()[file_name] = dataframes[f'{file_name}']\n",
    "    \n",
    "    del dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_userwithdraw['year_month'] = accounts_userwithdraw['created_at'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = accounts_userwithdraw[accounts_userwithdraw['year_month'] == '2023-07']\n",
    "con['reason'].value_counts() / con.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_user[accounts_user['firebase_uid'].isna()]\n",
    "\n",
    "def find_null_col(df):\n",
    "    null_rows = df[df.isna().any(axis=1)]\n",
    "    display(null_rows)\n",
    "\n",
    "find_null_col(accounts_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_paymenthistory['productId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_userquestionrecord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_userquestionrecord['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question['date'] = polls_question['created_at'].dt.strftime('%Y-%m-%d')\n",
    "polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 형태소 분석 함수\n",
    "def preprocess(text):\n",
    "    okt = Okt()\n",
    "    return okt.nouns(text) ## morphs, nouns\n",
    "\n",
    "# 명사 추출\n",
    "polls_question['nouns'] = polls_question['question_text'].apply(preprocess)\n",
    "\n",
    "# 모든 문서의 명사 합치고 빈도수 계산\n",
    "all_nouns = polls_question['nouns'].sum()\n",
    "counts = Counter(all_nouns)\n",
    "\n",
    "# 워드 클라우드 생성\n",
    "path = 'C:/Users/seoho/AppData/Local/Microsoft/Windows/Fonts/NanumSquare.ttf'\n",
    "wordcloud = WordCloud(font_path='malgun', background_color='white')\n",
    "wordcloud_image = wordcloud.generate_from_frequencies(counts)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud_image, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"polls_quesition Word Cloud\")\n",
    "\n",
    "plt.savefig('wordcloud.png', dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question.iloc[5022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# DataFrame의 'nouns' 컬럼에서 모든 명사를 하나의 리스트로 합칩니다.\n",
    "all_nouns = polls_question['nouns'].sum()\n",
    "\n",
    "# Counter를 사용하여 각 단어의 빈도를 계산합니다.\n",
    "word_counts = Counter(all_nouns)\n",
    "\n",
    "# 결과확인\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question[polls_question['id'] == 3115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionpiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polls_questionset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionset['opening_time'] = np.where(polls_questionset['opening_time'] < polls_questionset['created_at'], polls_questionset['created_at'], polls_questionset['opening_time'])\n",
    "polls_questionset['open_diff'] = polls_questionset['opening_time'] - polls_questionset['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionset['open_diff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionset['date'] = polls_questionset['opening_time'].dt.strftime('%Y-%m-%d')\n",
    "polls_questionset['year_month'] = polls_questionset['opening_time'].dt.to_period(\"M\")\n",
    "polls_questionset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionset['year_month'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polls_questionpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionpiece['year_month'] = polls_questionpiece['created_at'].dt.to_period(\"M\")\n",
    "polls_questionpiece['date'] = polls_questionpiece['created_at'].dt.strftime(\"%Y-%m-%d\")\n",
    "polls_questionpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_question = polls_questionpiece.groupby('year_month')['question_id'].value_counts().to_frame(name='count').reset_index(level='question_id')\n",
    "popular_question\n",
    "# pop_quest_df = pd.DataFrame(popular_question)\n",
    "# pop_quest_df\n",
    "\n",
    "popular_question.loc['2023-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question.rename(columns={'id' : 'question_id'}, inplace=True)\n",
    "polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_months = popular_question.index.get_level_values(0).unique()\n",
    "best_question = []\n",
    "\n",
    "for year_month in year_months:\n",
    "    loc = popular_question.loc[f'{year_month}'][:20]\n",
    "    merged_df = pd.merge(loc, polls_question, on='question_id', how='left')\n",
    "    merged_df['year_month'] = year_month\n",
    "    filtered_data = merged_df.query(f\"question_text != 'vote'\").head(10)\n",
    "    best_question.append(filtered_data)\n",
    "    #print(question_texts)\n",
    "\n",
    "\n",
    "# best_question[12]\n",
    "\n",
    "result_df = pd.concat(best_question, ignore_index=True)\n",
    "result_df.to_csv('question.csv')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_table = polls_questionpiece.groupby('question_id')['question_id'].value_counts()\n",
    "top_question = question_table.sort_values(ascending=False).to_frame(name='count').reset_index(level='question_id')\n",
    "top_question_df = pd.merge(top_question, polls_question, on='question_id', how='left')\n",
    "top_question_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question[polls_question['question_text'] == 'vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(popular_question, polls_question, on='question_id', how='left')\n",
    "\n",
    "\n",
    "# 병합된 데이터프레임에서 'question_text' 열 추출\n",
    "question_texts = merged_df['question_text']\n",
    "\n",
    "print(question_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_receipts['event_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_userquestionrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_usercandidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_pointhistory[accounts_pointhistory['delta_point'] < 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_paymenthistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_df = accounts_paymenthistory.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_df['point'] = payment_df['productId'].str.split('.').str[1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_last_datetime(series):\n",
    "    return series.min(), series.max()\n",
    "\n",
    "user_payment_df  = payment_df.groupby('user_id').agg({\n",
    "    'productId' : list, \n",
    "    'created_at' : list, \n",
    "    'point' : 'sum'})\n",
    "\n",
    "user_payment_df .columns = ['products', 'purchase_dates', 'total_purchases']\n",
    "\n",
    "\n",
    "user_payment_df .reset_index(level=0, inplace=True)\n",
    "user_payment_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_purchase = accounts_paymenthistory.groupby(accounts_paymenthistory['created_at'].dt.to_period(\"M\"))['productId'].count()\n",
    "\n",
    "# 시각화\n",
    "monthly_purchase.plot(kind='bar')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Purchase Count')\n",
    "plt.title('Monthly Purchase Count')\n",
    "plt.xticks(rotation=45)  # x축 라벨 회전 (필요에 따라 조절)\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### votes_accounts_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_user['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls_questionpiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선기님 data 추출\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pointhistory_df = accounts_pointhistory\n",
    "userquestionrecord_df = accounts_userquestionrecord\n",
    "questionpiece_df = polls_questionpiece\n",
    "event_receipts_df = event_receipts\n",
    "question_df = polls_question\n",
    "\n",
    "# 데이터 결합: 단계별 점검\n",
    "# Step 1: accounts_pointhistory -> accounts_userquestionrecord 결합\n",
    "merged_data = pointhistory_df.merge(userquestionrecord_df, left_on='user_question_record_id', right_on='id', how='left')\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Step 2: accounts_userquestionrecord -> polls_questionpiece 결합\n",
    "if 'question_piece_id' in merged_data.columns:  # 컬럼 존재 여부 확인\n",
    "    merged_data = merged_data.merge(questionpiece_df, left_on='question_piece_id', right_on='id', how='left')\n",
    "else:\n",
    "    raise KeyError(\"`question_piece_id` 컬럼이 누락되었습니다.\")\n",
    "\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Step 3: polls_questionpiece -> polls_question 결합\n",
    "merged_data.rename(columns={'question_id_x': 'question_id', 'created_at': 'question_created_at'}, inplace= True)\n",
    "question_df.rename(columns={'id': 'question_id'}, inplace= True)\n",
    "\n",
    "if 'question_id' in merged_data.columns:  # 컬럼 존재 여부 확인\n",
    "    merged_data = merged_data.merge(question_df, left_on='question_id', right_on='question_id', how='left')\n",
    "else:\n",
    "    raise KeyError(\"`question_id` 컬럼이 누락되었습니다.\")\n",
    "\n",
    "# 최종 데이터 확인\n",
    "print(\"최종 결합된 데이터:\\n\", merged_data.head())\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "selected_columns = ['delta_point', 'question_id', 'has_read', 'answer_status', 'report_count', 'opened_times', 'is_voted', 'is_skipped', 'question_text']\n",
    "\n",
    "# 선택한 컬럼으로 데이터 프레임을 재구성\n",
    "selected_data = merged_data[selected_columns]\n",
    "\n",
    "# 결과 출력\n",
    "display(selected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grouped의 dataframe에서 OKT를 거친 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: NaN 제거\n",
    "# NaN 또는 값이 없는 delta_point를 제거\n",
    "filtered_data = selected_data.dropna(subset=['question_id', 'has_read', 'is_voted', 'is_skipped'])\n",
    "\n",
    "# Step 2: 필요 없는 delta_point 값 필터링 (0인 질문 제거)\n",
    "filtered_data = filtered_data[filtered_data['question_id'] != 0]\n",
    "\n",
    "# Step 3: delta_point 값별로 주요 특징 그룹화\n",
    "grouped = filtered_data.groupby('delta_point').agg({\n",
    "    'question_id': 'nunique',  # 고유 질문 수\n",
    "    'has_read': 'mean',  # 질문 읽기 비율\n",
    "    'is_voted': 'mean',  # 질문 투표 비율\n",
    "    'is_skipped': 'mean',  # 질문 스킵 비율\n",
    "    'report_count': 'sum',  # 신고 횟수 합계\n",
    "    'opened_times': 'sum',  # 열린 횟수 합계\n",
    "    'question_text': lambda x: list(x.unique())  # 고유 질문 텍스트 리스트\n",
    "}).reset_index()\n",
    "\n",
    "# Step 4: 컬럼 이름 변경\n",
    "grouped.rename(columns={\n",
    "    'question_id': 'unique_questions',\n",
    "    'has_read': 'avg_has_read',\n",
    "    'is_voted': 'avg_is_voted',\n",
    "    'is_skipped': 'avg_is_skipped',\n",
    "    'report_count': 'total_reports',\n",
    "    'opened_times': 'total_opened',\n",
    "    'question_text': 'related_questions'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 5: 결과 출력\n",
    "print(\"Delta Point 기준 엔터티:\\n\")\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okt_nouns(text):\n",
    "    okt = Okt()\n",
    "    return okt.nouns(text) ## nouns\n",
    "\n",
    "def okt_morphs(text):\n",
    "    okt = Okt()\n",
    "    return okt.morphs(text) ## morphs\n",
    "\n",
    "\n",
    "# 명사 추출\n",
    "grouped['nouns'] = grouped['related_questions'].apply(lambda x: okt_nouns(' '.join(x)))\n",
    "\n",
    "\n",
    "grouped['morphs'] = grouped['related_questions'].apply(lambda x: okt_morphs(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv(\"grouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 리스트를 개별 항목으로 분리\n",
    "exploded_data = grouped.explode('related_questions')\n",
    "\n",
    "# Step 2: 각 question_text가 연결된 delta_point 목록 만들기\n",
    "question_delta_mapping = exploded_data.groupby('related_questions')['delta_point'].unique().reset_index()\n",
    "\n",
    "# Step 3: delta_point 목록 길이 계산\n",
    "question_delta_mapping['num_delta_points'] = question_delta_mapping['delta_point'].apply(len)\n",
    "\n",
    "# Step 4: 같은 질문이 여러 delta_point 값에서 나타나는지 확인\n",
    "repeated_questions = question_delta_mapping[question_delta_mapping['num_delta_points'] > 1]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"같은 질문이 여러 delta_point 값에서 나타나는 경우:\")\n",
    "display(repeated_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polls_question Category\n",
    "- 투표 관련하여 시제 및 문장 상태에 대해서 카테고리 분류\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶ Warnings 제거\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "question_df = polls_question.copy()\n",
    "question_df.head()\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 불필요한 문자 제거 함수\n",
    "def clean_text(text):\n",
    "    # 따옴표 및 특수문자 제거\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수문자 제거\n",
    "    text = text.strip()  # 앞뒤 공백 제거\n",
    "    return text\n",
    "\n",
    "# question_text 컬럼에 적용\n",
    "question_df['cleaned_question_text'] = question_df['question_text'].apply(clean_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(question_df[['question_text', 'cleaned_question_text']])\n",
    "\n",
    "# 'cleaned_question_text' 값이 'vote'인 행 삭제\n",
    "question_df = question_df[question_df['cleaned_question_text'] != 'vote']\n",
    "\n",
    "# 데이터프레임의 크기 확인\n",
    "print(f\"Updated dataframe shape: {question_df.shape}\")\n",
    "\n",
    "# 삭제 결과 확인\n",
    "display(question_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df['nouns'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 의도 분류 함수\n",
    "def classify_intent(text):\n",
    "    if any(word in text for word in ['어떻게', '방법', '해야', '갈래', '가자', '마실']):\n",
    "        return '행동 요청'\n",
    "    elif any(word in text for word in ['슬프다', '행복', '기쁨', '감정', '감성', '고마운',\n",
    "                                       '시원', '미워', '신경', '이성', '호감', '이쁘다', '이뻐',\n",
    "                                       '좋아', '귀여워', '너', '부르면', '널', '연락', '생각']):\n",
    "        return '감정 표현'\n",
    "    elif any(word in text for word in ['만약', '면', '상상', '같은', '같았던', '줄 수', '미래',\n",
    "                                       '싶다', '싶어', '할']):\n",
    "        return '상상/가정'\n",
    "    elif any(word in text for word in ['누가', '더 잘', '비교', '중요', '더 나은', '가까운',\n",
    "                                       '많은', '어울리는', '가장', '제일', '왕', '엄친',\n",
    "                                       '우리학교', '모태', '인간', '고인물', 'ACE', 'GOAT',\n",
    "                                       '최고', '만렙']):\n",
    "        return '판단/비교 요청'\n",
    "    elif any(word in text for word in ['왜', '이유', '과정', '매력', '좋은', '잘하는', 'mbti',\n",
    "                                       '성애자', '상', '싶은', '는', '사람', '친구', '덕후', \n",
    "                                       '트렌드', '알고보니', '파', '가까울']):\n",
    "        return '설명 요청'\n",
    "    else:\n",
    "        return '기타'\n",
    "        \n",
    "def classify_tone(text):\n",
    "    if any(word in text for word in ['잘', '제일', '아름다운', '멋진', '좋은', '웃', '성실', '어울리는', \n",
    "                                     '센스', '고마운', '스며드는', '풍부한', '미워할 수 없는', '예의바른',\n",
    "                                     '시원', '많', '매력', '어른', '넘사벽', '듬직', '귀여운', '꼼꼼한',\n",
    "                                     '이쁜', '꿇리지 않는', '나은', '대박', '잘생긴', '재밌는', '예쁜',\n",
    "                                     '창의적인', '옷', '유행', '스타일', 'ACE', '트렌드', '최고', '실물파',\n",
    "                                     '인간샤넬', '원탑', '만능', '성공', '완벽', '열심', '만능', '비주얼','성숙',\n",
    "                                     '호감', '좋아할', '볼매', '필요', '소중', '굉장하다', '미쳤다', '엄친', '프리패스',\n",
    "                                     '이쁘다']):\n",
    "        return '칭찬'\n",
    "    else:\n",
    "        return '호기심'\n",
    "\n",
    "\n",
    "#시간 분류 함수\n",
    "def classify_time(text):\n",
    "    if any(word in text for word in ['했던', '년 전', '돌아간다면', '것이다', '였던', '인 적', '었을', '봤',\n",
    "                                     '했']):\n",
    "        return '과거'\n",
    "    elif any(word in text for word in ['후', '미래', '년 뒤', '나중에', '선생님이 될', '다면', '되면', '꾸릴',\n",
    "                                       '수능', '2세', '년이 지나', '갈거 같은', '합격할 것', '년 안에',\n",
    "                                       '뒤에', '결혼', '내년', '살 것', '20살', '성인', '대학교', '성공할 것',\n",
    "                                       '100만구독자', '졸업 후', '어른이 되면', '대학가서']):\n",
    "        return '미래'\n",
    "    else:\n",
    "        return '현재'\n",
    "    \n",
    "# 데이터프레임에 의도, 톤, 시간 추가\n",
    "question_df['intent'] = question_df['cleaned_question_text'].apply(classify_intent)\n",
    "question_df['tone'] = question_df['cleaned_question_text'].apply(classify_tone)\n",
    "question_df['time_frame'] = question_df['cleaned_question_text'].apply(classify_time)\n",
    "\n",
    "# 레이블 매핑\n",
    "intent_mapping = {\n",
    "    '감정 표현': 0,\n",
    "    '상상/가정': 1,\n",
    "    '판단/비교 요청': 2,\n",
    "    '설명 요청': 3,\n",
    "    '행동 요청': 4,\n",
    "    '기타': 5\n",
    "}\n",
    "\n",
    "tone_mapping = {\n",
    "    '칭찬': 0,\n",
    "    '호기심': 1\n",
    "}\n",
    "\n",
    "time_mapping = {\n",
    "    '과거': 0,\n",
    "    '현재': 1,\n",
    "    '미래': 2,\n",
    "    '알 수 없음': 3\n",
    "}\n",
    "\n",
    "# 레이블 추가\n",
    "question_df['intent_label'] = question_df['intent'].map(intent_mapping)\n",
    "question_df['tone_label'] = question_df['tone'].map(tone_mapping)\n",
    "question_df['time_label'] = question_df['time_frame'].map(time_mapping)\n",
    "\n",
    "question_df = question_df[~question_df['intent_label'].isin([4, 5])]\n",
    "\n",
    "\n",
    "\n",
    "# 결과 확인\n",
    "display(question_df[['cleaned_question_text',  'tone', 'tone_label', 'intent', 'intent_label', 'time_frame', 'time_label']].head())\n",
    "\n",
    "question_df = question_df[['question_id', 'created_at', 'cleaned_question_text','tone', 'tone_label', 'intent', 'intent_label', 'time_frame', 'time_label']] \n",
    "\n",
    "question_df.to_csv('./data/question_categorize.csv', encoding= 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
